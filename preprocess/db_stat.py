from fastapi import FastAPI, File, UploadFile
from fastapi.responses import JSONResponse
import uvicorn
import os
from dotenv import load_dotenv
import pandas as pd

from pinecone import Pinecone, ServerlessSpec
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain_pinecone import PineconeVectorStore
from langchain_openai import OpenAIEmbeddings
from langchain_upstage import UpstageEmbeddings
from langchain_upstage import UpstageEmbeddings
from tqdm import tqdm
import yaml

from utils import *

load_dotenv(dotenv_path="../backend/.env")
prompts = yaml.safe_load(open("prompts.yaml", "r", encoding="utf-8"))

### Summarizer model
model = Upstage(api_key=os.getenv("UPSTAGE_API_KEY"))
pc = Pinecone(api_key=os.getenv("PINECONE_API_KEY"))
collection = "korea-jd-test"



app = FastAPI()
def check_index(collection: str="korea-jd-test"):
    """
    ì¸ë±ìŠ¤ ì¡´ì¬ ì—¬ë¶€ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    """
    index_name = collection
    if pc.has_index(index_name):
        return {"message": True}
    else:
        return {"message": False}



@app.get("/list_indexes")
async def list_indexes():
    """
    í˜„ì¬ ì¡´ì¬í•˜ëŠ” ëª¨ë“  Pinecone ì¸ë±ìŠ¤ì˜ ì´ë¦„ê³¼ ê°œìˆ˜ë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.
    
    return: 
        - total_count: ì „ì²´ ì¸ë±ìŠ¤ ê°œìˆ˜
        - indexes: ì¸ë±ìŠ¤ ì´ë¦„ ë¦¬ìŠ¤íŠ¸
    """
    try:
        indexes = pc.list_indexes()
        index_names = [index.name for index in indexes]
        
        return {
            "total_count": len(index_names),
            "indexes": index_names
        }
    except Exception as e:
        return JSONResponse(
            status_code=500,
            content={"message": f"ì¸ë±ìŠ¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}"}
        )


@app.get("/stat")
async def stat(collection: str="korea-jd-test"):
    """
    indexì˜ ìƒíƒœë¥¼ ì¡°íšŒí•©ë‹ˆë‹¤.

    parameter:
        collection: ì¸ë±ìŠ¤ ì´ë¦„
    return: ì¸ë±ìŠ¤ ìƒíƒœ
        [vector_count]ì— í‘œê¸°ë˜ëŠ” ë°±í„° ê°œìˆ˜ëŠ” ë°ì´í„° ê°œìˆ˜ê°€ ì•„ë‹ˆë¼ ì²­í‚¹ì´ ì™„ë£Œëœ ë°±í„° ê°œìˆ˜ì…ë‹ˆë‹¤.
    """
    index_name = collection
    result = check_index(collection)
    if result["message"]:
        index = pc.Index(index_name)
        stat = index.describe_index_stats()
        stat = stat.to_dict()
        return stat
    else:
        return {"message": "ì¸ë±ìŠ¤ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤"}


@app.get("/check_unique_columns")
async def check_unique_column(file: UploadFile,):
    """
    ë°ì´í„°í”„ë ˆì„ì˜ ê³ ìœ  ì»¬ëŸ¼ì„ ì¡°íšŒí•©ë‹ˆë‹¤.
    ### ì¶”í›„ êµ¬í˜„ ì˜ˆì •
    """
    uploaded_file = file.file
    df = pd.read_csv(uploaded_file)





@app.get("/create_index")
async def create_index(index_name: str = "index-name-for-create", dimension: int=4096):
    """
    Pinecone ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ëŠ” API
    """
    try:
        # ì¸ë±ìŠ¤ ìƒì„±
        pc.create_index(
            index_name,
            dimension=dimension,
            metric="cosine",
            spec=ServerlessSpec(
                cloud="aws",
                region="us-east-1"
            )
        )
        # ìƒì„±ëœ ì¸ë±ìŠ¤ ê°ì²´ ë¡œë“œ
        return {
            "index_name": index_name,
            "status": "success",
            "detail": "Index created successfully."
        }
    except Exception as e:
        # Pinecone ì—ëŸ¬ ë©”ì‹œì§€ë¥¼ ê·¸ëŒ€ë¡œ ì „ë‹¬
        return {
            "index_name": index_name,
            "status": "error",
            "detail": str(e)
        }

@app.get("/drop_index")
async def drop_index(collection: str="index-name-for-drop"):
    """
    ì¸ë±ìŠ¤ë¥¼ ì‚­ì œí•©ë‹ˆë‹¤.
    """
    try:
        index_name = collection
        pc.delete_index(name=index_name)
        return {
            "index_name": index_name,
            "status": "success",
            "detail": "Index deleted successfully."
        }
    except Exception as e:
        return {
            "index_name": index_name,
            "status": "error",
            "detail": str(e)
        }


# @app.post("/upsert_data")
# async def upsert_jd(file: UploadFile, collection: str="korea-jd-dev"):
#     """
#     CSVë¥¼ ì—…ë¡œë“œí•˜ê³  Pineconeì— ì €ì¥í•©ë‹ˆë‹¤.
#     """
#     if not file.filename.endswith('.csv'):
#         return JSONResponse(
#             status_code=400, 
#             content={"message": "CSV íŒŒì¼ë§Œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."}
#         )

#     try: 
#         ### ìš”ì•½ì „ ì¸ë±ìŠ¤ ë¶€í„° chk
#         index_name = collection
#         result = check_index(collection)
#         index = pc.Index(index_name)

#         uploaded_file = file.file
#         df = pd.read_csv(uploaded_file)





@app.post("/upsert_jd")
async def update_index(file: UploadFile, collection: str="korea-jd-dev"):
    """
    - korea-jd-dev: ê°œë°œìš©
    - korea-jd-prod: ë°°í¬ìš©

    """
    if not file.filename.endswith('.csv'):
        
        # CSV íŒŒì¼ì´ ì•„ë‹Œ ê²½ìš° ì˜¤ë¥˜ ì²˜ë¦¬
        return JSONResponse(
            status_code=400, 
            content={"message": "CSV íŒŒì¼ë§Œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."}
        )
    try: 
        ### ìš”ì•½ì „ ì¸ë±ìŠ¤ ë¶€í„° chk
        index_name = collection
        result = check_index(collection)
        index = pc.Index(index_name)
        ids = get_all_ids(index)
        url_set = set()
        date_dicts = {}
        for id in tqdm(ids, desc="Getting URLs from Pinecone"):
            row = get_metadata_by_id(index, id)
            url_set.add(row["job_url"])
            date_dicts[id] = row["deadline"]
            # url_set.add(get_metadata_by_id(index, id)["job_url"])
        print(url_set)
        if result == False:
            raise ValueError("Index check failed: result is False")

        uploaded_file = file.file
        df = pd.read_csv(uploaded_file)
        print(f"ğŸ“Š CSVì—ì„œ ì½ì€ ë°ì´í„°: {len(df)}ê°œ")
        print(f"ğŸ“Š Pineconeì— ìˆëŠ” URL: {len(url_set)}ê°œ")
        
        # INSERT_YOUR_CODE
        # df["url"] ì»¬ëŸ¼ì—ì„œ url_setì— ì¡´ì¬í•˜ëŠ” urlì´ ìˆëŠ” í–‰ ì œê±°
        before = len(df)
        df = df[~df["url"].isin(url_set)].reset_index(drop=True)
        removed = before - len(df)
        after = len(df)
        
        print(f"ğŸ“Š ì²˜ë¦¬ ì „: {before}ê°œ")
        print(f"ğŸ“Š ì²˜ë¦¬ í›„: {after}ê°œ")
        print(f"ğŸ“Š ì œê±°ëœ í–‰: {removed}ê°œ")

        delete_ids = []
        for k, v in date_dicts.items():
            if check_deadline(v)==False:
                delete_ids.append(k)
        delete_vectors(index, delete_ids)
        print(f"âœ… {len(delete_ids)}ê°œì˜ ë²¡í„°ê°€ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.")

        total_chunks = preprocess(df)

        # index = pc.Index(index_name)

        # emb_model = OpenAIEmbeddings()
        emb_model = UpstageEmbeddings(model="solar-embedding-1-large")

        vector_store = PineconeVectorStore(index=index, embedding=emb_model)

        ### ë°ì´í„°ê°€ ë‚¨ì•„ìˆì„ë•Œ ë°ì´í„° ì œê±°(ì†ŒëŸ‰ì¼ë•Œë§Œ ì‚¬ìš©), ì¶”í›„ ëª¨ë“ˆí™”
        # if len(index.describe_index_stats()["namespaces"]) > 0:
        #     index.delete(delete_all=True, namespace="")

        ### íŒŒì¸ì½˜ APIë¡œ í•œë²ˆì— ëŒ€ìš©ëŸ‰ updateê°€ ë¶ˆê°€ëŠ¥í•˜ì—¬ ë°°ì¹˜ì²˜ë¦¬
        total = len(total_chunks)
        batch_size = 100
        for start in tqdm(range(0, total, batch_size), desc="Upserting to Pinecone"):
            end = start + batch_size
            batch_docs = total_chunks[start:end]
            # print(batch_docs)
            vector_store.add_documents(documents=batch_docs)
        return JSONResponse(
            status_code=200, 
            content={"message": "ì¸ë±ìŠ¤ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤"}
        )

    except Exception as e:
        return JSONResponse(
            status_code=500, 
            content={"message": str(e)}
        )


@app.post("/upsert_custom_csv")
async def update_index(file: UploadFile, collection: str="test-custom-index"):
    """
    - korea-jd-dev, korea-jd-prod ì‚¬ìš©ë¶ˆê°€

    """
    if not file.filename.endswith('.csv'):
        
        # CSV íŒŒì¼ì´ ì•„ë‹Œ ê²½ìš° ì˜¤ë¥˜ ì²˜ë¦¬
        return JSONResponse(
            status_code=400, 
            content={"message": "CSV íŒŒì¼ë§Œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."}
        )
    try: 
        ### ìš”ì•½ì „ ì¸ë±ìŠ¤ ë¶€í„° chk
        index_name = collection
        result = check_index(collection)
        if result["message"] == False:
            index = await create_index(index_name)
        else:
            index = pc.Index(index_name)
        uploaded_file = file.file
        df = pd.read_csv(uploaded_file)
        total_chunks = make_documents_from_csv(df)
        emb_model = UpstageEmbeddings(model="solar-embedding-1-large")

        vector_store = PineconeVectorStore(index=index, embedding=emb_model)

        ### ë°ì´í„°ê°€ ë‚¨ì•„ìˆì„ë•Œ ë°ì´í„° ì œê±°(ì†ŒëŸ‰ì¼ë•Œë§Œ ì‚¬ìš©), ì¶”í›„ ëª¨ë“ˆí™”
        if len(index.describe_index_stats()["namespaces"]) > 0:
            index.delete(delete_all=True, namespace="")

        ### íŒŒì¸ì½˜ APIë¡œ í•œë²ˆì— ëŒ€ìš©ëŸ‰ updateê°€ ë¶ˆê°€ëŠ¥í•˜ì—¬ ë°°ì¹˜ì²˜ë¦¬
        total = len(total_chunks)
        batch_size = 100
        for start in tqdm(range(0, total, batch_size), desc="Upserting to Pinecone"):
            end = start + batch_size

            batch_docs = total_chunks[start:end]
            # print(batch_docs)
            vector_store.add_documents(documents=batch_docs)
        return JSONResponse(
            status_code=200, 
            content={"message": "ì¸ë±ìŠ¤ê°€ ì—…ë°ì´íŠ¸ë˜ì—ˆìŠµë‹ˆë‹¤"}
        )

    except Exception as e:
        return JSONResponse(
            status_code=500, 
            content={"message": str(e)}
        )



if __name__ == "__main__":
    uvicorn.run(app, host="0.0.0.0", port=8000)