# %%
import os
import re
import json
import time
import asyncio
import numpy as np
import openai
from groq import Groq
import matplotlib.pyplot as plt
from io import BytesIO
import base64
from datetime import datetime
from dotenv import load_dotenv
import markdown

# ë‚´ë¶€ ëª¨ë“ˆ ì„í¬íŠ¸
from ..system.parser import run_parser
from . import prompts


class ATSAnalyzer:
    """
    Advanced ATS (Applicant Tracking System) Analyzer
    ì´ í´ë˜ìŠ¤ëŠ” ì´ë ¥ì„œì™€ ì±„ìš© ê³µê³ ë¥¼ ë¶„ì„í•˜ì—¬ ATS ì‹œìŠ¤í…œì´ ì´ë ¥ì„œë¥¼ ì–´ë–»ê²Œ í‰ê°€í•˜ëŠ”ì§€ ì‹œë®¬ë ˆì´ì…˜í•˜ê³ ,
    ìƒì„¸í•œ í”¼ë“œë°±ê³¼ ê°œì„  ì œì•ˆì„ ì œê³µí•©ë‹ˆë‹¤.
    """

    def __init__(self, cv_path, jd_text, model=1):
        """
        ATS ë¶„ì„ê¸° ì´ˆê¸°í™”

        Args:
            cv_path (str): ì´ë ¥ì„œ íŒŒì¼ ê²½ë¡œ (PDF, DOCX, TXT) ë˜ëŠ” ì›ì‹œ í…ìŠ¤íŠ¸
            jd_text (str): ì±„ìš© ê³µê³  í…ìŠ¤íŠ¸
            model (int): ëª¨ë¸ ì„ íƒ (1=OpenAI, 2=Groq, 3=Gemini)
        """
        self.cv_path = cv_path
        self.jd_text = jd_text
        self.model = model
        
        # ë¶„ì„ ê³¼ì • ë° ê²°ê³¼ë¥¼ ì €ì¥í•  ë³€ìˆ˜ë“¤
        self.cv_text = ""
        self.preprocessed_cv = ""
        self.structured_cv = {}
        self.jd_analysis = {}
        self.jd_requirements = []
        self.jd_keywords = []
        
        self.analysis_results = {}
        self.scores = {}
        self.final_report = ""
        self.improvement_suggestions = ""
        self.competitive_analysis = ""
        self.optimized_resume = ""
        
        # ì„±ëŠ¥ ë° ì‚¬ìš©ëŸ‰ ì¶”ì  ë³€ìˆ˜
        self.llm_call_count = 0
        self.total_tokens = 0
        self.total_time = 0

        # .env íŒŒì¼ì—ì„œ API í‚¤ ë¡œë“œ ë° LLM í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        load_dotenv()
        self._initialize_llm_clients()

    def _initialize_llm_clients(self):
        """í™˜ê²½ ë³€ìˆ˜ì—ì„œ API í‚¤ë¥¼ ì½ì–´ LLM í´ë¼ì´ì–¸íŠ¸ë¥¼ ì´ˆê¸°í™”í•©ë‹ˆë‹¤."""
        self.openai_client = None
        self.groq_client = None
        self.gemini_client = None

        # OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        openai_api_key = os.getenv("OPENAI_API_KEY")
        if openai_api_key and openai_api_key != "your_openai_api_key_here":
            self.openai_client = openai.AsyncOpenAI(api_key=openai_api_key)
        else:
            print("ê²½ê³ : OpenAI API í‚¤ê°€ .env íŒŒì¼ì— ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        # Groq í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        groq_api_key = os.getenv("GROQ_API_KEY")
        if groq_api_key and groq_api_key != "your_groq_api_key_here":
            try:
                # Groq SDKëŠ” í˜„ì¬ ë™ê¸° ë°©ì‹ë§Œ ê³µì‹ ì§€ì›í•˜ë¯€ë¡œ,
                # ë¹„ë™ê¸° í˜¸ì¶œì„ ìœ„í•´ ë™ê¸° í´ë¼ì´ì–¸íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
                self.groq_client = Groq(api_key=groq_api_key)
            except ImportError:
                print("ê²½ê³ : 'groq' íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. `pip install groq`ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
            except Exception as e:
                print(f"Groq í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        else:
            print("ê²½ê³ : Groq API í‚¤ê°€ .env íŒŒì¼ì— ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")

        # Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (OpenAI í˜¸í™˜ ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©)
        gemini_api_key = os.getenv("GEMINI_API_KEY")
        if gemini_api_key and gemini_api_key != "your_gemini_api_key_here":
            try:
                # Gemini APIë¥¼ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ í˜•ì‹ìœ¼ë¡œ ì‚¬ìš©í•˜ê¸° ìœ„í•œ ì„¤ì •
                self.gemini_client = openai.AsyncOpenAI(api_key=gemini_api_key, base_url="https://generativelanguage.googleapis.com/v1beta/openai/")
            except Exception as e:
                print(f"Gemini í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        else:
            print("ê²½ê³ : Gemini API í‚¤ê°€ .env íŒŒì¼ì— ì—†ê±°ë‚˜ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")


    async def extract_and_preprocess(self):
        """ì´ë ¥ì„œ íŒŒì¼ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ê³  ì „ì²˜ë¦¬í•©ë‹ˆë‹¤."""
        try:
            # upstage-parserë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë ¥ì„œ ë‚´ìš© ì¶”ì¶œ
            _, _, full_contents = run_parser(self.cv_path)
            text = full_contents
        except Exception as e:
            print(f"ì´ë ¥ì„œ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            text = ""

        self.cv_text = text.strip()
        self.structured_cv = self._extract_resume_sections(self.cv_text)
        self.preprocessed_cv = self._advanced_preprocessing(self.cv_text)
        
        # ì±„ìš© ê³µê³  ë¶„ì„ì€ ë‹¤ë¥¸ ë¶„ì„ì˜ ì„ í–‰ ì‘ì—…ì´ë¯€ë¡œ awaitë¡œ ì™„ë£Œë¥¼ ê¸°ë‹¤ë¦½ë‹ˆë‹¤.
        await self.analyze_job_description()

        print(f"ì´ë ¥ì„œì—ì„œ {len(self.cv_text)}ì ì¶”ì¶œ ì™„ë£Œ")
        print(f"ì´ë ¥ì„œì—ì„œ {len(self.structured_cv)}ê°œì˜ ì„¹ì…˜ ì‹ë³„ ì™„ë£Œ")
        print(f"ì±„ìš© ê³µê³  ë¶„ì„ ì™„ë£Œ, {len(self.jd_keywords)}ê°œì˜ í‚¤ì›Œë“œ ì¶”ì¶œ ì™„ë£Œ")

    async def analyze_job_description(self):
        """
        ì±„ìš© ê³µê³ ë¥¼ ë¶„ì„í•˜ì—¬ ìš”êµ¬ì‚¬í•­, í‚¤ì›Œë“œ ë° ê¸°íƒ€ ì¤‘ìš”í•œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.
        ì´ ë‹¨ê³„ëŠ” ATS ë¶„ì„ì„ íŠ¹ì • ì§ë¬´ì— ë§ê²Œ ì¡°ì •í•˜ëŠ” ë° ë§¤ìš° ì¤‘ìš”í•©ë‹ˆë‹¤.
        """
        jd_analysis_prompt = prompts.get_jd_analysis_prompt(self.jd_text)
        
        max_retries = 2
        for attempt in range(max_retries):
            response = await self.call_llm(jd_analysis_prompt)
            
            try:
                self.jd_analysis = self._parse_json_from_llm(response)
                
                # ë¶„ì„ëœ JDì—ì„œ í‚¤ì›Œë“œ ë° ìš”êµ¬ì‚¬í•­ ëª©ë¡ ì¶”ì¶œ
                self.jd_keywords = self.jd_analysis.get('keywords', [])
                self.jd_requirements = (
                    self.jd_analysis.get('required_qualifications', []) +
                    self.jd_analysis.get('preferred_qualifications', []) +
                    self.jd_analysis.get('technical_skills', []) +
                    self.jd_analysis.get('soft_skills', []) +
                    self.jd_analysis.get('industry_knowledge', [])
                )
                print(f"JD ë¶„ì„ JSON íŒŒì‹± ì„±ê³µ, {len(self.jd_keywords)}ê°œ í‚¤ì›Œë“œ ì¶”ì¶œ")
                return # ì„±ê³µ ì‹œ í•¨ìˆ˜ ì¢…ë£Œ
            except (json.JSONDecodeError, SyntaxError) as e:
                print(f"JD ë¶„ì„ JSON íŒŒì‹± ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                if attempt == max_retries - 1:
                    print("ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. ëŒ€ì²´ìš© ê¸°ë³¸ JD ë¶„ì„ êµ¬ì¡°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.")
                    self._create_default_jd_analysis()

    def _create_default_jd_analysis(self):
        """JD ë¶„ì„ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë”ë¯¸ ë°ì´í„°ë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        self.jd_analysis = {
            "required_qualifications": ["Master's degree", "1+ years of experience"],
            "preferred_qualifications": ["PhD", "Industry experience"],
            "key_responsibilities": ["Research", "Development", "Collaboration"],
            "technical_skills": ["Python", "Machine Learning", "Deep Learning"],
            "soft_skills": ["Communication", "Teamwork"],
            "industry_knowledge": ["AI Research", "Software Development"],
            "company_values": ["Innovation", "Collaboration"],
            "keywords": [
                {"keyword": "Python", "importance": 9, "category": "Technical Skill"},
                {"keyword": "Machine Learning", "importance": 8, "category": "Technical Skill"}
            ]
        }
        self.jd_keywords = self.jd_analysis["keywords"]
        self.jd_requirements = (
            self.jd_analysis["required_qualifications"] +
            self.jd_analysis["preferred_qualifications"]
        )

    def _parse_json_from_llm(self, response_text: str):
        """
        LLM ì‘ë‹µì—ì„œ JSON ê°ì²´ë¥¼ ë” ì•ˆì •ì ìœ¼ë¡œ ì¶”ì¶œí•˜ê³  íŒŒì‹±í•©ë‹ˆë‹¤.
        - ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡(```json ... ```) ì œê±°
        - ë¶ˆí•„ìš”í•œ ì ‘ë‘/ì ‘ë¯¸ì‚¬ ì œê±°
        - í”í•œ JSON ì˜¤ë¥˜ ìë™ ìˆ˜ì •
        """
        # LLM ì‘ë‹µì—ì„œ ì½”ë“œ ë¸”ë¡(```json ... ```)ì„ ì°¾ì•„ ë‚´ìš©ë§Œ ì¶”ì¶œ
        match = re.search(r'```json\s*([\s\S]*?)\s*```', response_text)
        if match:
            response_text = match.group(1)
        
        # ì²« '{'ì™€ ë§ˆì§€ë§‰ '}' ì‚¬ì´ì˜ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•˜ì—¬ ë¶ˆí•„ìš”í•œ ì ‘ë‘/ì ‘ë¯¸ì‚¬ ì œê±°
        start_idx = response_text.find('{')
        end_idx = response_text.rfind('}')
        if start_idx != -1 and end_idx != -1 and end_idx > start_idx:
            response_text = response_text[start_idx:end_idx+1]

        try:
            return json.loads(response_text)
        except json.JSONDecodeError as e:
            print(f"JSON íŒŒì‹± 1ì°¨ ì‹œë„ ì‹¤íŒ¨: {e}. ìë™ ìˆ˜ì •ì„ ì‹œë„í•©ë‹ˆë‹¤.")
            # í›„í–‰ ì‰¼í‘œ(trailing comma)ì™€ ê°™ì€ í”í•œ ì˜¤ë¥˜ ìˆ˜ì •
            text = re.sub(r',\s*([}\]])', r'\1', response_text)
            
            try:
                return json.loads(text)
            except json.JSONDecodeError as final_e:
                print(f"JSON ìë™ ìˆ˜ì • í›„ íŒŒì‹± ìµœì¢… ì‹¤íŒ¨: {final_e}")
                # ì˜¤ë¥˜ ì •ë³´ë¥¼ í¬í•¨í•˜ì—¬ ì˜ˆì™¸ ë°œìƒ
                raise SyntaxError("LLMìœ¼ë¡œë¶€í„° ìœ íš¨í•œ JSONì„ íŒŒì‹±í•˜ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.") from final_e


    def _extract_resume_sections(self, text: str) -> dict:
        """ì •ê·œì‹ì„ ì‚¬ìš©í•˜ì—¬ ì´ë ¥ì„œ í…ìŠ¤íŠ¸ë¥¼ êµ¬ì¡°í™”ëœ ì„¹ì…˜ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        # ì´ë ¥ì„œì˜ ì¼ë°˜ì ì¸ ì„¹ì…˜ ì œëª© íŒ¨í„´
        section_patterns = {
            'personal_info': r'^(Personal\s*Information|Contact|Profile)$',
            'summary': r'^(Summary|Professional\s*Summary|Profile|Objective)$',
            'education': r'^(Education|Academic|Qualifications|Degrees)$',
            'experience': r'^(Experience|Work\s*Experience|Employment|Career\s*History)$',
            'skills': r'^(Skills|Technical\s*Skills|Competencies|Expertise)$',
            'projects': r'^(Projects|Key\s*Projects|Professional\s*Projects)$',
            'certifications': r'^(Certifications|Certificates|Accreditations)$',
            'languages': r'^(Languages|Language\s*Proficiency)$',
            'publications': r'^(Publications|Research|Papers)$',
            'awards': r'^(Awards|Honors|Achievements|Recognitions)$'
        }
        
        sections = {}
        current_section = 'header'  # ì²« ì„¹ì…˜ ì œëª©ì´ ë‚˜ì˜¤ê¸° ì „ê¹Œì§€ì˜ ë‚´ìš©ì€ í—¤ë”ë¡œ ê°„ì£¼
        sections[current_section] = []

        lines = text.split('\n')
        for line in lines:
            line_stripped = line.strip()
            if not line_stripped:
                continue

            matched = False
            for section_name, pattern in section_patterns.items():
                # ì„¹ì…˜ ì œëª©ì€ ë³´í†µ í•œ ì¤„ì„ ë‹¤ ì°¨ì§€í•˜ë¯€ë¡œ, ë¼ì¸ ì „ì²´ê°€ íŒ¨í„´ê³¼ ì¼ì¹˜í•˜ëŠ”ì§€ í™•ì¸
                if re.fullmatch(pattern, line_stripped, re.IGNORECASE):
                    current_section = section_name
                    if current_section not in sections:
                        sections[current_section] = []
                    matched = True
                    break
            
            if not matched:
                if current_section not in sections:
                    sections[current_section] = []
                sections[current_section].append(line)
        
        # ê° ì„¹ì…˜ì˜ ë¼ì¸ë“¤ì„ í•˜ë‚˜ì˜ í…ìŠ¤íŠ¸ ë¸”ë¡ìœ¼ë¡œ í•©ì¹¨
        for section, section_lines in sections.items():
            sections[section] = '\n'.join(section_lines).strip()
            
        return sections

    def _advanced_preprocessing(self, text: str) -> str:
        """ì´ë ¥ì„œ ë¶„ì„ì„ ìœ„í•œ ê³ ê¸‰ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬. ë¶ˆí•„ìš”í•œ ê³µë°±ê³¼ ì¤„ë°”ê¿ˆì„ ì •ë¦¬í•©ë‹ˆë‹¤."""
        text = re.sub(r'[ \t]+', ' ', text)  # ì—¬ëŸ¬ ê³µë°±/íƒ­ì„ í•˜ë‚˜ì˜ ê³µë°±ìœ¼ë¡œ
        text = re.sub(r'\n{3,}', '\n\n', text) # ê³¼ë„í•œ ì¤„ë°”ê¿ˆì„ ë‘ê°œë¡œ ì œí•œ
        return text.strip()

    async def analyze_keywords(self):
        """ì´ë ¥ì„œê°€ ì±„ìš© ê³µê³ ì˜ í•µì‹¬ ìš©ì–´ì™€ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ ë¶„ì„í•©ë‹ˆë‹¤."""
        prompt = prompts.get_keyword_analysis_prompt(
            jd_analysis=self.jd_analysis,
            jd_keywords=self.jd_keywords,
            resume_text=self.preprocessed_cv
        )
        response = await self.call_llm(prompt)
        print("[DEBUG] í‚¤ì›Œë“œ ë¶„ì„ LLM ì‘ë‹µ:\n", response[:200], "...")
        score = self._extract_score(response)
        print("[DEBUG] í‚¤ì›Œë“œ ì ìˆ˜:", score)
        self.analysis_results['keywords'] = response
        self.scores['keywords'] = score

    async def analyze_experience_and_qualifications(self):
        """ì´ë ¥ì„œì˜ ê²½ë ¥ ë° ìê²©ì´ ì§ë¬´ ìš”êµ¬ì‚¬í•­ê³¼ ì–¼ë§ˆë‚˜ ì¼ì¹˜í•˜ëŠ”ì§€ ë¶„ì„í•©ë‹ˆë‹¤."""
        prompt = prompts.get_experience_analysis_prompt(self.jd_text, self.preprocessed_cv)
        response = await self.call_llm(prompt)
        print("[DEBUG] ê²½ë ¥ ë¶„ì„ LLM ì‘ë‹µ:\n", response[:200], "...")
        score = self._extract_score(response)
        print("[DEBUG] ê²½ë ¥ ì ìˆ˜:", score)
        self.analysis_results['experience'] = response
        self.scores['experience'] = score

    async def analyze_format_and_readability(self):
        """ì´ë ¥ì„œì˜ í˜•ì‹, êµ¬ì¡°, ê°€ë…ì„±ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        prompt = prompts.get_format_analysis_prompt(self.preprocessed_cv)
        response = await self.call_llm(prompt)
        print("[DEBUG] í˜•ì‹ ë¶„ì„ LLM ì‘ë‹µ:\n", response[:200], "...")
        score = self._extract_score(response)
        print("[DEBUG] í˜•ì‹ ì ìˆ˜:", score)
        self.analysis_results['format'] = response
        self.scores['format'] = score

    async def analyze_content_quality(self):
        """ì´ë ¥ì„œ ë‚´ìš©ì˜ í’ˆì§ˆì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        prompt = prompts.get_content_quality_prompt(self.preprocessed_cv)
        response = await self.call_llm(prompt)
        print("[DEBUG] ë‚´ìš© í’ˆì§ˆ ë¶„ì„ LLM ì‘ë‹µ:\n", response[:200], "...")
        score = self._extract_score(response)
        print("[DEBUG] ë‚´ìš© í’ˆì§ˆ ì ìˆ˜:", score)
        self.analysis_results['content'] = response
        self.scores['content'] = score

    async def check_errors_and_consistency(self):
        """ì´ë ¥ì„œì˜ ì˜¤ë¥˜, ë¶ˆì¼ì¹˜, ìœ„í—˜ ì‹ í˜¸ë¥¼ í™•ì¸í•©ë‹ˆë‹¤."""
        prompt = prompts.get_error_check_prompt(self.preprocessed_cv)
        response = await self.call_llm(prompt)
        print("[DEBUG] ì˜¤ë¥˜ ë¶„ì„ LLM ì‘ë‹µ:\n", response[:200], "...")
        score = self._extract_score(response)
        print("[DEBUG] ì˜¤ë¥˜ ì ìˆ˜:", score)
        self.analysis_results['errors'] = response
        self.scores['errors'] = score

    async def analyze_semantic_keyword_match(self):
        """
        LLMì„ ì‚¬ìš©í•˜ì—¬ í‚¤ì›Œë“œì˜ ì˜ë¯¸ì  ì¼ì¹˜ë„ë¥¼ ë¶„ì„í•˜ê³  ì ìˆ˜ë¥¼ ë§¤ê¹ë‹ˆë‹¤.
        ê¸°ì¡´ì˜ ë‹¨ìˆœ í…ìŠ¤íŠ¸ ë§¤ì¹­ ë°©ì‹ì¸ simulate_ats_filteringì„ ëŒ€ì²´í•©ë‹ˆë‹¤.
        """
        if not self.jd_keywords:
            print("JD ë¶„ì„ì—ì„œ í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì˜ë¯¸ë¡ ì  í‚¤ì›Œë“œ ë¶„ì„ì„ ê±´ë„ˆë›°ìŠµë‹ˆë‹¤.")
            self.analysis_results['ats_simulation'] = "JD ë¶„ì„ì—ì„œ í‚¤ì›Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            self.scores['ats_simulation'] = 0
            return

        prompt = prompts.get_semantic_keyword_analysis_prompt(self.jd_keywords, self.preprocessed_cv)
        
        try:
            response_str = await self.call_llm(prompt)
            analysis_data = self._parse_json_from_llm(response_str)

            keyword_matches = analysis_data.get("keyword_matches", [])
            summary = analysis_data.get("semantic_analysis_summary", "ìš”ì•½ ì •ë³´ ì—†ìŒ.")
            
            if not keyword_matches:
                raise ValueError("LLM ì‘ë‹µì—ì„œ í‚¤ì›Œë“œ ë§¤ì¹­ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

            total_importance = sum(kw.get('importance', 5) for kw in keyword_matches)
            if total_importance == 0:
                self.scores['ats_simulation'] = 0
                self.analysis_results['ats_simulation'] = "ë¶„ì„ëœ í‚¤ì›Œë“œì˜ ì¤‘ìš”ë„ ì ìˆ˜ê°€ ì—†ì–´ ì ìˆ˜ë¥¼ ê³„ì‚°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                return

            matched_score = 0
            status_weights = {'matched': 1.0, 'semantically_present': 0.75, 'missing': 0.0}

            for match in keyword_matches:
                status = match.get('status', 'missing')
                importance = match.get('importance', 5)
                weight = status_weights.get(status, 0.0)
                matched_score += importance * weight
            
            final_score = (matched_score / total_importance) * 100

            # ë³´ê³ ì„œ ìƒì„±
            report_parts = [
                f"## ATS Semantic Analysis Results\n",
                f"### Overall Semantic Score: {final_score:.1f}/100\n",
                f"**ìš”ì•½:** {summary}\n",
                "| Keyword | Status | Justification | Importance | Category |",
                "|---|---|---|---|---|"
            ]
            
            status_map = {
                'matched': 'âœ… Matched',
                'semantically_present': 'ğŸ’¡ Semantically Present',
                'missing': 'âŒ Missing'
            }
            
            for item in sorted(keyword_matches, key=lambda x: x.get('importance', 0), reverse=True):
                status_display = status_map.get(item['status'], item['status'])
                report_parts.append(
                    f"| {item['keyword']} | **{status_display}** | {item['justification']} | {item['importance']}/10 | {item['category']} |"
                )

            self.analysis_results['ats_simulation'] = "\n".join(report_parts)
            self.scores['ats_simulation'] = final_score

        except (json.JSONDecodeError, SyntaxError, ValueError) as e:
            print(f"ì˜ë¯¸ë¡ ì  í‚¤ì›Œë“œ ë¶„ì„ ì‹¤íŒ¨: {e}. ì´ì „ ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            self.analysis_results['ats_simulation'] = "ì˜ë¯¸ë¡ ì  í‚¤ì›Œë“œ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."
            self.scores['ats_simulation'] = 20 # ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ì ìˆ˜


    async def analyze_industry_specific(self):
        """ì‚°ì—… ë° ì§ë¬´ë³„ íŠ¹í™” ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤."""
        # 1. LLMì„ ì‚¬ìš©í•˜ì—¬ ì‚°ì—… ë° ì§ë¬´ ì—­í•  ì‹ë³„
        industry_prompt = prompts.get_industry_identification_prompt(self.jd_text)
        response = await self.call_llm(industry_prompt)
        
        try:
            job_info = self._parse_json_from_llm(response)
            industry = job_info.get('industry', 'General')
            job_role = job_info.get('job_role', 'General')
        except (json.JSONDecodeError, SyntaxError) as e:
            print(f"ì‚°ì—… ì •ë³´ JSON íŒŒì‹± ì˜¤ë¥˜: {e}. ê¸°ë³¸ê°’ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
            industry, job_role = "Technology", "Professional"

        # 2. ì‹ë³„ëœ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‚°ì—…ë³„ ë¶„ì„ ìˆ˜í–‰
        industry_analysis_prompt = prompts.get_industry_specific_analysis_prompt(
            job_role=job_role,
            industry=industry,
            jd_text=self.jd_text,
            resume_text=self.preprocessed_cv
        )
        response = await self.call_llm(industry_analysis_prompt)
        score = self._extract_score(response)

        self.analysis_results['industry_specific'] = response
        self.scores['industry_specific'] = score

    async def suggest_resume_improvements(self):
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì´ë ¥ì„œ ê°œì„ ì„ ìœ„í•œ êµ¬ì²´ì ì¸ ì œì•ˆì„ ìƒì„±í•©ë‹ˆë‹¤."""
        prompt = prompts.get_improvement_suggestion_prompt(
            jd_text=self.jd_text,
            resume_text=self.preprocessed_cv,
            scores=self.scores
        )
        response = await self.call_llm(prompt)
        self.improvement_suggestions = response
        return response

    async def analyze_competitive_position(self):
        """í˜„ì¬ ì±„ìš© ì‹œì¥ì—ì„œ ì´ë ¥ì„œì˜ ê²½ìŸë ¥ì„ ë¶„ì„í•©ë‹ˆë‹¤."""
        prompt = prompts.get_competitive_analysis_prompt(
            jd_text=self.jd_text,
            resume_text=self.preprocessed_cv
        )
        response = await self.call_llm(prompt)
        # ê²½ìŸë ¥ ì ìˆ˜ëŠ” ë‹¤ë¥¸ ì ìˆ˜ í˜•ì‹ê³¼ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë³„ë„ ì²˜ë¦¬
        score_match = re.search(r'Competitive Score:\s*(\d+)/100', response, re.IGNORECASE)
        if score_match:
            score = int(score_match.group(1))
        else:
            score = self._extract_score(response)
        
        self.analysis_results['competitive'] = response
        self.scores['competitive'] = score
        return response

    async def generate_optimized_resume(self):
        """ì±„ìš© ê³µê³ ì— ë§ì¶° ìµœì í™”ëœ ì´ë ¥ì„œ ë²„ì „ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        prompt = prompts.get_resume_optimization_prompt(
            jd_text=self.jd_text,
            resume_text=self.preprocessed_cv
        )
        response = await self.call_llm(prompt)
        self.optimized_resume = response
        return response

    async def generate_final_score_and_recommendations(self):
        """ê°€ì¤‘ì¹˜ë¥¼ ì ìš©í•œ ìµœì¢… ì ìˆ˜ì™€ ì „ë°˜ì ì¸ ê¶Œì¥ ì‚¬í•­ì„ ìƒì„±í•©ë‹ˆë‹¤."""
        # ê° ë¶„ì„ í•­ëª©ì— ëŒ€í•œ ê°€ì¤‘ì¹˜ ì •ì˜
        weights = {
            'ats_simulation': 0.30,    # ATS ì‹œë®¬ë ˆì´ì…˜ì´ ê°€ì¥ ì¤‘ìš”
            'keywords': 0.25,         # í‚¤ì›Œë“œ ì¼ì¹˜ë„
            'experience': 0.20,       # ê²½ë ¥ ë¶€í•©ë„
            'industry_specific': 0.15, # ì‚°ì—… ì „ë¬¸ì„±
            'content': 0.05,          # ë‚´ìš© í’ˆì§ˆ
            'format': 0.03,           # í˜•ì‹ ë° ê°€ë…ì„±
            'errors': 0.02,           # ì˜¤ë¥˜ ë° ì¼ê´€ì„±
        }
        
        # ê°€ì¤‘ í‰ê·  ì ìˆ˜ ê³„ì‚°
        weighted_sum = sum(self.scores.get(cat, 0) * w for cat, w in weights.items() if cat in self.scores)
        used_weights_sum = sum(w for cat, w in weights.items() if cat in self.scores)
        final_score = weighted_sum / used_weights_sum if used_weights_sum > 0 else 0
        self.scores['final'] = final_score

        # ìµœì¢… ë³´ê³ ì„œ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ í˜¸ì¶œ
        prompt = prompts.get_final_report_prompt(
            jd_analysis=self.jd_analysis,
            scores=self.scores,
            final_score=final_score
        )
        response = await self.call_llm(prompt)
        self.final_report = f"## OVERALL ATS ANALYSIS SCORE: {final_score:.1f}/100\n\n{response}"

    def generate_visual_report(self, output_path="ats_report.html"):
        """ì°¨íŠ¸ì™€ ì„œì‹ì´ ì§€ì •ëœ ë¶„ì„ì„ í¬í•¨í•˜ëŠ” ì‹œê°ì ì¸ HTML ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        try:
            # ì ìˆ˜ ì‹œê°í™”ë¥¼ ìœ„í•œ ë ˆì´ë” ì°¨íŠ¸ ìƒì„±
            chart_base64 = self._create_radar_chart()
            
            # ë§ˆí¬ë‹¤ìš´ì„ HTMLë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜
            def md_to_html(text: str) -> str:
                if not text:
                    return "<p>ë‚´ìš© ì—†ìŒ</p>"
                try:
                    # fenced_code: ì½”ë“œ ë¸”ë¡ ì§€ì›, tables: í‘œ ì§€ì›
                    # nl2br í™•ì¥ ê¸°ëŠ¥ì€ í‘œ ë Œë”ë§ê³¼ ì¶©ëŒí•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì œê±°í•©ë‹ˆë‹¤.
                    return markdown.markdown(text, extensions=['fenced_code', 'tables'])
                except Exception as e:
                    print(f"ë§ˆí¬ë‹¤ìš´ ë³€í™˜ ì˜¤ë¥˜: {e}")
                    # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ <pre> íƒœê·¸ë¡œ ê°ì‹¸ì„œ ì•ˆì „í•˜ê²Œ í‘œì‹œ
                    return f"<pre>{text}</pre>"

            # prompts ëª¨ë“ˆì˜ í…œí”Œë¦¿ì„ ì‚¬ìš©í•˜ì—¬ HTML ì»¨í…ì¸  ìƒì„±
            html_content = prompts.get_html_report_template(
                final_score=self.scores.get('final', 0),
                chart_image=chart_base64,
                final_report_md=md_to_html(self.final_report),
                ats_simulation_md=md_to_html(self.analysis_results.get('ats_simulation', 'ë¶„ì„ ì •ë³´ ì—†ìŒ')),
                improvements_md=md_to_html(self.improvement_suggestions),
                scores=self.scores,
                analysis_results=self.analysis_results,
                md_to_html_func=md_to_html
            )
            
            # ìƒì„±ëœ HTMLì„ íŒŒì¼ì— ì €ì¥
            with open(output_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
            
            return output_path

        except Exception as e:
            print(f"ì‹œê°ì  ë³´ê³ ì„œ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return None

    def _create_radar_chart(self) -> str:
        """ì ìˆ˜ ë ˆì´ë” ì°¨íŠ¸ë¥¼ ìƒì„±í•˜ê³  base64ë¡œ ì¸ì½”ë”©ëœ ì´ë¯¸ì§€ ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤."""
        categories = ['Keywords', 'Experience', 'ATS Sim', 'Industry Fit', 'Content', 'Format', 'Errors']
        score_keys = ['keywords', 'experience', 'ats_simulation', 'industry_specific', 'content', 'format', 'errors']
        values = [self.scores.get(key, 0) for key in score_keys]
        
        if len(values) != len(categories):
             print("ê²½ê³ : ì°¨íŠ¸ ìƒì„±ì— í•„ìš”í•œ ì ìˆ˜ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")
             return ""

        fig = plt.figure(figsize=(8, 8))
        ax = fig.add_subplot(111, polar=True)
        
        # ê°ë„ ê³„ì‚° ë° í”Œë¡¯ ë‹«ê¸°
        angles = np.linspace(0, 2 * np.pi, len(categories), endpoint=False).tolist()
        values += values[:1]
        angles += angles[:1]

        # í”Œë¡¯ ìŠ¤íƒ€ì¼ ì„¤ì •
        ax.plot(angles, values, 'o-', linewidth=2, color='blue')
        ax.fill(angles, values, 'skyblue', alpha=0.25)
        ax.set_thetagrids(np.degrees(angles[:-1]), categories)
        ax.set_ylim(0, 100)
        ax.set_rlabel_position(22.5)
        ax.grid(True)
        plt.title('Resume ATS Analysis Results', size=16, color='blue', y=1.1)

        # ì´ë¯¸ì§€ë¥¼ ë©”ëª¨ë¦¬ ë²„í¼ì— ì €ì¥í•˜ì—¬ base64ë¡œ ì¸ì½”ë”©
        buffer = BytesIO()
        plt.savefig(buffer, format='png', bbox_inches='tight')
        buffer.seek(0)
        img_str = base64.b64encode(buffer.read()).decode()
        plt.close(fig)
        return img_str

    def generate_text_report(self):
        """ë¶„ì„ì— ëŒ€í•œ í…ìŠ¤íŠ¸ ê¸°ë°˜ ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤."""
        report = "=== ATS ANALYSIS REPORT ===\n\n"
        report += f"FINAL SCORE: {self.scores.get('final', 0):.1f}/100\n\n"
        report += "SCORE BREAKDOWN:\n"
        for cat in ['keywords', 'experience', 'ats_simulation', 'format', 'content', 'errors', 'industry_specific']:
            report += f"- {cat.replace('_', ' ').title()}: {self.scores.get(cat, 'N/A')}/100\n"
        report += "\nEXECUTIVE SUMMARY:\n"
        # ìµœì¢… ë³´ê³ ì„œëŠ” ë§ˆí¬ë‹¤ìš´ í˜•ì‹ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        summary_text = re.sub(r'##.*?\n', '', self.final_report)
        report += f"{summary_text}\n\n"
        report += "RECOMMENDED IMPROVEMENTS:\n"
        report += f"{self.improvement_suggestions}\n\n"
        report += "USAGE STATISTICS:\n"
        report += f"- LLM API Calls: {self.llm_call_count}\n"
        report += f"- Total Tokens Used: {self.total_tokens}\n"
        report += f"- Analysis Time: {self.total_time:.2f} seconds\n"
        return report

    async def call_llm(self, prompt: str, model: int = None) -> str:
        """
        ì„ íƒëœ ëª¨ë¸ì— ë”°ë¼ LLM APIë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ í˜¸ì¶œí•˜ê³ ,
        í˜¸ì¶œ ì‹œê°„, íšŸìˆ˜, í† í° ì‚¬ìš©ëŸ‰ì„ ì¶”ì í•©ë‹ˆë‹¤.
        """
        if model is None:
            model = self.model
        
        call_start_time = time.time()
        
        try:
            response_content = ""
            if model == 1:
                response_content = await self._call_openai(prompt)
            elif model == 2:
                response_content = await self._call_groq(prompt)
            elif model == 3:
                 response_content = await self._call_gemini(prompt)
            else:
                print(f"ì˜¤ë¥˜: ì˜ëª»ëœ ëª¨ë¸ ì„ íƒ({model})")
                return self._generate_dummy_response(prompt)
            
            return response_content

        except Exception as e:
            print(f"LLM API í˜¸ì¶œ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ (ëª¨ë¸ {model}): {e}")
            return await self._fallback_llm_call(prompt)
        finally:
            # ê°œë³„ LLM í˜¸ì¶œ ì‹œê°„ì€ ì „ì²´ ë¶„ì„ ì‹œê°„ì— í•©ì‚°
            pass

    async def _call_openai(self, prompt: str) -> str:
        """OpenAI APIë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤."""
        if not self.openai_client:
            raise ValueError("OpenAI í´ë¼ì´ì–¸íŠ¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        
        model="gpt-4.1-nano-2025-04-14"
        print(f"OpenAI model: {model}")
        response = await self.openai_client.chat.completions.create(
            model=model, # ìµœì‹  ë° ë” ê°•ë ¥í•œ ëª¨ë¸ë¡œ ë³€ê²½
            messages=[
                {"role": "system", "content": "You are an expert resume analyst and ATS specialist. Respond in well-formatted Markdown."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=3000 # ë” ê¸´ ì‘ë‹µì„ ìœ„í•´ í† í° ìˆ˜ ì¦ê°€
        )
        self.llm_call_count += 1
        if response.usage:
            self.total_tokens += response.usage.total_tokens
        return response.choices[0].message.content.strip()

    async def _call_groq(self, prompt: str) -> str:
        """Groq APIë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤. (ë¹„ë™ê¸° ì²˜ë¦¬ë¥¼ ìœ„í•´ asyncio.to_thread ì‚¬ìš©)"""
        if not self.groq_client:
            raise ValueError("Groq í´ë¼ì´ì–¸íŠ¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

        model="meta-llama/llama-4-maverick-17b-128e-instruct"
        print(f"Groq model: {model}")
        # Groqì˜ ë™ê¸° SDKë¥¼ ë¹„ë™ê¸° ì´ë²¤íŠ¸ ë£¨í”„ì—ì„œ ë¸”ë¡œí‚¹ ì—†ì´ ì‹¤í–‰
        def sync_groq_call():
            return self.groq_client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "You are an expert resume analyst and ATS specialist. Respond in well-formatted Markdown."},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.1,
                max_tokens=3000,
                top_p=1,
                stream=False
            )
        
        completion = await asyncio.to_thread(sync_groq_call)

        self.llm_call_count += 1
        if completion.usage:
            self.total_tokens += completion.usage.total_tokens
        return completion.choices[0].message.content.strip()
        
    async def _call_gemini(self, prompt: str) -> str:
        """Gemini APIë¥¼ ë¹„ë™ê¸°ì ìœ¼ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤. (OpenAI í˜¸í™˜)"""
        if not self.gemini_client:
            raise ValueError("Gemini í´ë¼ì´ì–¸íŠ¸ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        model="gemini-2.5-flash-preview-05-20"
        print(f"Gemini model: {model}")
        response = await self.gemini_client.chat.completions.create(
            model=model, # ëª¨ë¸ëª…ì€ ì‹¤ì œ Gemini ëª¨ë¸ì— ë§ê²Œ í™•ì¸ í•„ìš”
            messages=[
                {"role": "system", "content": "You are an expert resume analyst and ATS specialist. Respond in well-formatted Markdown."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.1,
            max_tokens=3000
        )
        self.llm_call_count += 1
        if hasattr(response, 'usage') and response.usage:
            self.total_tokens += response.usage.total_tokens
        
        # Gemini APIê°€ ì•ˆì „ í•„í„° ë“±ì— ì˜í•´ ë¹„ì–´ìˆëŠ” ì‘ë‹µì„ ë³´ë‚¼ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ë°©ì–´ ì½”ë“œ
        choice = response.choices[0]
        if choice.message.content is None:
            finish_reason = getattr(choice, 'finish_reason', 'N/A')
            print(f"ê²½ê³ : Gemini APIê°€ ë¹„ì–´ ìˆëŠ” ì½˜í…ì¸ ë¥¼ ë°˜í™˜í–ˆìŠµë‹ˆë‹¤. ì¢…ë£Œ ì‚¬ìœ : {finish_reason}")
            # ì•ˆì „ ì„¤ì • ë“±ìœ¼ë¡œ ì¸í•´ ì½˜í…ì¸ ê°€ ë°˜í™˜ë˜ì§€ ì•Šì€ ê²½ìš°, ì‚¬ìš©ìì—ê²Œ ì •ë³´ë¥¼ ì œê³µí•˜ê³  ë¹„ì–´ ìˆëŠ” ë¬¸ìì—´ì„ ë°˜í™˜í•©ë‹ˆë‹¤.
            return f"Gemini APIê°€ ì½˜í…ì¸ ë¥¼ ë°˜í™˜í•˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¢…ë£Œ ì‚¬ìœ : {finish_reason}"
        
        return choice.message.content.strip()

    async def _fallback_llm_call(self, prompt: str) -> str:
        """ì£¼ LLM í˜¸ì¶œ ì‹¤íŒ¨ ì‹œ ëŒ€ì²´ ê°€ëŠ¥í•œ ë‹¤ë¥¸ LLMì„ ìˆœì„œëŒ€ë¡œ í˜¸ì¶œí•©ë‹ˆë‹¤."""
        print("ì£¼ìš” LLM í˜¸ì¶œ ì‹¤íŒ¨. ëŒ€ì²´ ëª¨ë¸ì„ ì‹œë„í•©ë‹ˆë‹¤...")
        
        # ì‹œë„í•´ë³¼ ëª¨ë¸ ëª©ë¡ (í˜„ì¬ ëª¨ë¸ ì œì™¸)
        fallback_models = {
            1: self._call_openai,
            2: self._call_groq,
            3: self._call_gemini,
        }
        
        for model_num, call_func in fallback_models.items():
            if model_num == self.model:
                continue
            
            try:
                print(f"{model_num}ë²ˆ ëª¨ë¸ë¡œ ëŒ€ì²´ í˜¸ì¶œì„ ì‹œë„í•©ë‹ˆë‹¤...")
                return await call_func(prompt)
            except Exception as e:
                print(f"{model_num}ë²ˆ ëª¨ë¸ í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                continue

        print("ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  LLM í´ë¼ì´ì–¸íŠ¸ í˜¸ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ë”ë¯¸ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤.")
        return self._generate_dummy_response(prompt)

    def _generate_dummy_response(self, prompt: str) -> str:
        """API í˜¸ì¶œ ì‹¤íŒ¨ ë˜ëŠ” API í‚¤ ë¶€ì¬ ì‹œ í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤."""
        print("ê²½ê³ : ë”ë¯¸ ì‘ë‹µì„ ìƒì„±í•©ë‹ˆë‹¤. ì‹¤ì œ ë¶„ì„ ê²°ê³¼ê°€ ì•„ë‹™ë‹ˆë‹¤.")
        
        # JSON ì‘ë‹µì„ ê¸°ëŒ€í•˜ëŠ” í”„ë¡¬í”„íŠ¸ì¸ì§€ í™•ì¸
        if "json" in prompt.lower():
            return '```json\n{"message": "This is a dummy JSON response.", "score": 50}\n```'
        
        return "This is a dummy response for testing purposes. In a real scenario, this would contain a detailed analysis based on your prompt.\n\nScore: 50 points"

    def _extract_score(self, response_text: str) -> int:
        """LLM ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ ì ìˆ˜ë¥¼ ì§€ëŠ¥ì ìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
        # ë‹¤ì–‘í•œ ì ìˆ˜ í˜•ì‹ íŒ¨í„´ ì •ì˜ (ê°€ì¥ êµ¬ì²´ì ì¸ ê²ƒë¶€í„°)
        patterns = [
            r'Score:\s*(\d{1,3})\s*points',
            r'Score:\s*(\d{1,3})',
            r'score of\s*(\d{1,3})',
            r'rated at\s*(\d{1,3})',
            r'(\d{1,3})\s*/\s*100',
            r'(\d{1,3})\s*out of\s*100'
        ]

        for pattern in patterns:
            match = re.search(pattern, response_text, re.IGNORECASE)
            if match:
                score = int(match.group(1))
                return max(0, min(100, score)) # ì ìˆ˜ë¥¼ 0-100 ì‚¬ì´ë¡œ ë³´ì •

        # í…ìŠ¤íŠ¸ì—ì„œ ì ìˆ˜ ì¶”ì¶œ ì‹¤íŒ¨ ì‹œ, JSON íŒŒì‹± ì‹œë„
        try:
            data = self._parse_json_from_llm(response_text)
            if 'overall_score' in data and isinstance(data['overall_score'], int):
                return max(0, min(100, data['overall_score']))
            if 'score' in data and isinstance(data['score'], int):
                return max(0, min(100, data['score']))
        except (SyntaxError, json.JSONDecodeError, TypeError, KeyError):
            pass # JSON íŒŒì‹±ì— ì‹¤íŒ¨í•˜ë©´ ë¬´ì‹œí•˜ê³  ê³„ì† ì§„í–‰

        print(f"ê²½ê³ : ì‘ë‹µì—ì„œ ì ìˆ˜ë¥¼ ì¶”ì¶œí•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ê°’ 50ì„ ì‚¬ìš©í•©ë‹ˆë‹¤. ì‘ë‹µ: '{response_text[:100]}...'")
        return 50

    async def run_full_analysis(self, advanced=True, generate_html=True):
        """
        ì „ì²´ ì´ë ¥ì„œ ë¶„ì„ì„ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì‹¤í–‰í•˜ì—¬ ì„±ëŠ¥ì„ ìµœì í™”í•©ë‹ˆë‹¤.

        Args:
            advanced (bool): ê³ ê¸‰ ë¶„ì„(ATS ì‹œë®¬ë ˆì´ì…˜, ê²½ìŸë ¥ ë¶„ì„ ë“±) ì‹¤í–‰ ì—¬ë¶€
            generate_html (bool): HTML ë³´ê³ ì„œ ìƒì„± ì—¬ë¶€

        Returns:
            str: ìƒì„±ëœ ë³´ê³ ì„œì˜ ê²½ë¡œ ë˜ëŠ” í…ìŠ¤íŠ¸ ë³´ê³ ì„œ ë‚´ìš©
        """
        analysis_start_time = time.time()
        print("ATS ë¶„ì„ì„ ì‹œì‘í•©ë‹ˆë‹¤...")

        # 1. ì „ì²˜ë¦¬ ë° JD ë¶„ì„ (ìˆœì°¨ ì‹¤í–‰ í•„ìš”)
        await self.extract_and_preprocess()
        print(f"ì±„ìš© ê³µê³ ë³„ íŠ¹í™”ëœ {len(self.jd_keywords)}ê°œì˜ í‚¤ì›Œë“œë¥¼ ë°”íƒ•ìœ¼ë¡œ ë¶„ì„ì„ ì§„í–‰í•©ë‹ˆë‹¤...")

        # 2. ë³‘ë ¬ ì‹¤í–‰í•  ë¶„ì„ ì‘ì—… ëª©ë¡ ìƒì„±
        # LLMì„ í˜¸ì¶œí•˜ëŠ” ë¹„ë™ê¸° ì‘ì—…ë“¤
        llm_tasks = [
            self.analyze_keywords(),
            self.analyze_experience_and_qualifications(),
            self.analyze_format_and_readability(),
            self.analyze_content_quality(),
            self.check_errors_and_consistency(),
        ]
        if advanced:
            print("ê³ ê¸‰ ë¶„ì„ì„ ë³‘ë ¬ë¡œ ì‹¤í–‰í•©ë‹ˆë‹¤...")
            llm_tasks.extend([
                self.analyze_industry_specific(),
                self.analyze_competitive_position(),
                self.analyze_semantic_keyword_match(),
            ])
        
        # 3. asyncio.gatherë¥¼ ì‚¬ìš©í•˜ì—¬ LLM í˜¸ì¶œì„ ë³‘ë ¬ë¡œ ì‹¤í–‰
        await asyncio.gather(*llm_tasks)
        
        # 4. LLM í˜¸ì¶œì´ ì—†ëŠ” ìˆœìˆ˜ ê³„ì‚° ì‘ì—… ì‹¤í–‰ (ë³‘ë ¬ ì²˜ë¦¬ í›„)
        # if advanced:
        #     await self.simulate_ats_filtering() # ì´ í•¨ìˆ˜ëŠ” ì´ì œ analyze_semantic_keyword_matchë¡œ ëŒ€ì²´ë¨

        # 5. í›„ì† ì‘ì—… (ìˆœì°¨ ì‹¤í–‰)
        print("ê°œì„  ì œì•ˆ ì‚¬í•­ì„ ìƒì„±í•©ë‹ˆë‹¤...")
        await self.suggest_resume_improvements()
        
        print("ìµœì í™”ëœ ì´ë ¥ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
        await self.generate_optimized_resume()

        print("ìµœì¢… ì ìˆ˜ ë° ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
        await self.generate_final_score_and_recommendations()

        self.total_time = time.time() - analysis_start_time
        print(f"ë¶„ì„ ì™„ë£Œ. ì´ ì†Œìš” ì‹œê°„: {self.total_time:.1f}ì´ˆ")
        self.print_usage_statistics()

        # 6. ìµœì¢… ë³´ê³ ì„œ ìƒì„±
        if generate_html:
            print("ì‹œê°ì ì¸ HTML ë³´ê³ ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤...")
            report_path = self.generate_visual_report()
            print(f"HTML ë³´ê³ ì„œ ìƒì„± ì™„ë£Œ: {report_path}")
            return report_path
        else:
            return self.generate_text_report()

    def print_usage_statistics(self):
        """ì½˜ì†”ì— ì‚¬ìš© í†µê³„ë¥¼ ì¶œë ¥í•©ë‹ˆë‹¤."""
        print("\n===== USAGE STATISTICS =====")
        print(f"LLM API Calls: {self.llm_call_count}")
        print(f"Total Tokens Used: {self.total_tokens}")
        print(f"Analysis Time: {self.total_time:.2f} seconds")

        print("\n===== SCORE BREAKDOWN =====")
        print(f"Final ATS Score: {self.scores.get('final', 0):.1f}/100")
        print(f"Keywords Match: {self.scores.get('keywords', 0)}/100")
        print(f"Experience Match: {self.scores.get('experience', 0)}/100")
        print(f"ATS Simulation (Semantic): {self.scores.get('ats_simulation', 0):.1f}/100")
        print(f"Format & Readability: {self.scores.get('format', 0)}/100")
        print(f"Content Quality: {self.scores.get('content', 0)}/100")
        print(f"Errors & Consistency: {self.scores.get('errors', 0)}/100")
        print(f"Industry Alignment: {self.scores.get('industry_specific', 0)}/100")
        print("============================\n")


async def main():
    """
    ATS ë¶„ì„ê¸° ì‹¤í–‰ì„ ìœ„í•œ ë©”ì¸ í•¨ìˆ˜.
    ì‚¬ìš©ìëŠ” ì´ í•¨ìˆ˜ ë‚´ì˜ ì„¤ì •ê°’ë§Œ ìˆ˜ì •í•˜ë©´ ë©ë‹ˆë‹¤.
    """
    # 1. ë¶„ì„í•  ì´ë ¥ì„œ íŒŒì¼ì˜ ê²½ë¡œë¥¼ ì§€ì •í•˜ì„¸ìš”.
    # íŒŒì¼ì˜ ì ˆëŒ€ê²½ë¡œë¥¼ ì…ë ¥í•˜ì„¸ìš”.
    cv_path = "GJS/JobPT/validate_agent/OpenAI_Solutions_Architect,_Digital_Natives_segment_CV.pdf" 
    
    # 2. ì‚¬ìš©í•  AI ëª¨ë¸ì„ ì„ íƒí•˜ì„¸ìš”. (1: OpenAI, 2: Groq, 3: Gemini)
    # .env íŒŒì¼ì— í•´ë‹¹ ëª¨ë¸ì˜ API í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.
    # 2ë²ˆì˜ Groqì˜ ê²½ìš° ë¬´ë£Œ tierëŠ” ë³‘ë ¬ ì²˜ë¦¬ ì‹œ ë¬¸ì œê°€ ë°œìƒí•˜ë¯€ë¡œ paid tierë¡œ ì—…ê·¸ë ˆì´ë“œ í›„ ì‚¬ìš© ê°€ëŠ¥ëŠ¥
    model = 1
    
    # 3. ê³ ê¸‰ ë¶„ì„(ê²½ìŸë ¥, ì‚°ì—… ì í•©ë„ ë“±)ì„ ì‹¤í–‰í• ì§€ ì—¬ë¶€ë¥¼ ì„ íƒí•˜ì„¸ìš”.
    advanced = True 
    
    # 4. ìµœì¢… ë¦¬í¬íŠ¸ë¥¼ HTML íŒŒì¼ë¡œ ìƒì„±í• ì§€ ì—¬ë¶€ë¥¼ ì„ íƒí•˜ì„¸ìš”.
    # Falseë¡œ ì„¤ì •í•˜ë©´, ì½˜ì†”ì— í…ìŠ¤íŠ¸ ìš”ì•½ë³¸ë§Œ ì¶œë ¥ë©ë‹ˆë‹¤.
    generate_html = True  

    # 5. ì•„ë˜ì— ë¶„ì„í•  ì±„ìš© ê³µê³ (Job Description) ì „ë¬¸ì„ ë³µì‚¬í•˜ì—¬ ë¶™ì—¬ë„£ìœ¼ì„¸ìš”.
    jd_text = """
About the team

The Solutions Architecture team is responsible for ensuring the safe and effective deployment of Generative AI applications for developers and enterprises. We act as a trusted advisor and thought partner for our customers, working to build an effective backlog of GenAI use cases for their industry and drive them to production through strong technical guidance. As a Solutions Architect in the Digital Natives segment, you'll help large and highly technical companies transform their business through solutions such as customer service, automated content generation, contextual search, personalization, and novel applications that make use of our newest, most exciting models.

About the role

We are looking for a driven solutions leader with a product mindset to partner with our customers and ensure they achieve tangible business value with GenAI. You will pair with senior customer leaders to establish a GenAI strategy and identify the highest value applications. You'll then partner with their engineering and product teams to move from prototype through production. You'll take a holistic view of their needs and design an enterprise architecture using OpenAI API and other services to maximize customer value. You will collaborate closely with Sales, Solutions Engineering, Applied Research, and Product teams.

This role is based in Seoul, South Korea. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.

In this role, you will:

Deeply embed with our most sophisticated and technical platform customers as the technical lead, serving as their technical thought partner to ideate and build novel applications on our API.

Work with senior customer stakeholders to identify the best applications of GenAI in their industry and to build/qualify a comprehensive backlog to support their AI roadmap.

Intervene directly to accelerate customer time to value through building hands-on prototypes and/or by delivering impactful strategic guidance.

Forge and manage relationships with our customers' leadership and stakeholders to ensure the successful deployment and scale of their applications.

Contribute to our open-source developer and enterprise resources.

Scale the Solutions Architect function through sharing knowledge, codifying best practices, and publishing notebooks to our internal and external repositories.

Validate, synthesize, and deliver high-signal feedback to the Product, Engineering, and Research teams.

You'll thrive in this role if you:

Have 5+ years of technical consulting (or equivalent) experience, bridging technical teams and senior business stakeholders.

Are an effective and polished communicator who can translate business and technical topics to all audiences.

Are proficient in both Korean and English. This is essential to effectively perform key responsibilities such as partnering with customers, driving the sales cycle, managing accounts, collaborating with cross-functional teams, and communicating with headquarters

Have led complex implementations of Generative AI/traditional ML solutions and have knowledge of network/cloud architecture.

Have industry experience in programming languages like Python or Javascript.

Own problems end-to-end and are willing to pick up whatever knowledge you're missing to get the job done.

Have a humble attitude, an eagerness to help your colleagues, and a desire to do whatever it takes to make the team succeed.

Are an effective, high throughput operator who can drive multiple concurrent projects and prioritize ruthlessly. 

About OpenAI

OpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity. 

We are an equal opportunity employer, and we do not discriminate on the basis of race, religion, color, national origin, sex, sexual orientation, age, veteran status, disability, genetic information, or other applicable legally protected characteristic.

For additional information, please see OpenAI's Affirmative Action and Equal Employment Opportunity Policy Statement.

Qualified applicants with arrest or conviction records will be considered for employment in accordance with applicable law, including the San Francisco Fair Chance Ordinance, the Los Angeles County Fair Chance Ordinance for Employers, and the California Fair Chance Act. For unincorporated Los Angeles County workers: we reasonably believe that criminal history may have a direct, adverse and negative relationship with the following job duties, potentially resulting in the withdrawal of a conditional offer of employment: protect computer hardware entrusted to you from theft, loss or damage; return all computer hardware in your possession (including the data contained therein) upon termination of employment or end of assignment; and maintain the confidentiality of proprietary, confidential, and non-public information. In addition, job duties require access to secure and protected information technology systems and related data security obligations.

We are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via this link.

OpenAI Global Applicant Privacy Policy

At OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.
"""

    analyzer = ATSAnalyzer(cv_path, jd_text, model=model)
    result = await analyzer.run_full_analysis(advanced=advanced, generate_html=generate_html)

    if not generate_html:
        print("\n=== TEXT REPORT ===")
        print(result)
    else:
        print(f"\në¶„ì„ ì™„ë£Œ! ë³´ê³ ì„œê°€ ì €ì¥ëœ ê²½ë¡œ: {result}")
        print("ì›¹ ë¸Œë¼ìš°ì €ì—ì„œ HTML íŒŒì¼ì„ ì—´ì–´ ì „ì²´ ë³´ê³ ì„œë¥¼ í™•ì¸í•˜ì„¸ìš”.")

if __name__ == "__main__":
    import time
    start_time = time.time()
    asyncio.run(main())
    end_time = time.time()
    print(f"\nì´ êµ¬ë™ ì‹œê°„: {end_time - start_time:.2f}ì´ˆ")


# %%
