{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ì´ë ¥ì„œ JSON íŒŒì„œ\n",
    "\n",
    "PDFì—ì„œ ì¶”ì¶œëœ JSON ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ì´ë ¥ì„œ ì •ë³´ë¥¼ ì¶”ì¶œí•©ë‹ˆë‹¤.\n",
    "\n",
    "## ì¶”ì¶œ ì •ë³´\n",
    "- âœ… ê¸°ë³¸ ì •ë³´ (ì´ë¦„, ì§ì±…)\n",
    "- âœ… ì—°ë½ì²˜ ì •ë³´ (ì´ë©”ì¼, ì „í™”ë²ˆí˜¸, GitHub, LinkedIn, ë¸”ë¡œê·¸)\n",
    "- âœ… ìê¸°ì†Œê°œ\n",
    "- âœ… ê²½ë ¥ ì •ë³´ (íšŒì‚¬, ì§ì±…, ê¸°ê°„, ì—…ë¬´, í”„ë¡œì íŠ¸)\n",
    "- âœ… í•™ë ¥ ì •ë³´ (í•™êµ, í•™ìœ„, ì „ê³µ, GPA)\n",
    "- âœ… ì¶œíŒë¬¼\n",
    "- âœ… ì±„ë„/ê¸°ìˆ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "from typing import Dict, List, Optional, Any\n",
    "from pathlib import Path\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. ResumeParser í´ë˜ìŠ¤ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResumeParser:\n",
    "    \"\"\"PDFì—ì„œ ì¶”ì¶œëœ JSON ë°ì´í„°ë¥¼ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ì´ë ¥ì„œ ì •ë³´ë¥¼ ì¶”ì¶œ\"\"\"\n",
    "    \n",
    "    def __init__(self, json_path: str):\n",
    "        self.json_path = Path(json_path)\n",
    "        self.data = None\n",
    "        self.elements = []\n",
    "        \n",
    "    def load_json(self) -> bool:\n",
    "        \"\"\"JSON íŒŒì¼ ë¡œë“œ\"\"\"\n",
    "        try:\n",
    "            with open(self.json_path, 'r', encoding='utf-8') as f:\n",
    "                self.data = json.load(f)\n",
    "                self.elements = self.data.get('elements', [])\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading JSON: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def parse(self) -> Dict[str, Any]:\n",
    "        \"\"\"ì „ì²´ ì´ë ¥ì„œ íŒŒì‹±\"\"\"\n",
    "        if not self.load_json():\n",
    "            return {}\n",
    "        \n",
    "        result = {\n",
    "            'basic_info': self._extract_basic_info(),\n",
    "            'contact_info': self._extract_contact_info(),\n",
    "            'introduction': self._extract_introduction(),\n",
    "            'work_experiences': self._extract_work_experiences(),\n",
    "            'education': self._extract_education(),\n",
    "            'projects': self._extract_projects(),\n",
    "            'publications': self._extract_publications(),\n",
    "            'certificates': self._extract_certificates(),\n",
    "            'awards': self._extract_awards(),\n",
    "            'skills_and_channels': self._extract_skills_and_channels(),\n",
    "        }\n",
    "        \n",
    "        return result\n",
    "    \n",
    "    def _get_text_by_category(self, category: str) -> List[Dict]:\n",
    "        \"\"\"íŠ¹ì • ì¹´í…Œê³ ë¦¬ì˜ ìš”ì†Œë“¤ ë°˜í™˜\"\"\"\n",
    "        return [elem for elem in self.elements if elem.get('category') == category]\n",
    "    \n",
    "    def _extract_basic_info(self) -> Dict[str, Optional[str]]:\n",
    "        \"\"\"ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ (ì´ë¦„)\"\"\"\n",
    "        basic_info = {\n",
    "            'name': None,\n",
    "            'title': None,\n",
    "        }\n",
    "        \n",
    "        # ì²« ë²ˆì§¸ heading1ì—ì„œ ì´ë¦„ ì¶”ì¶œ ì‹œë„\n",
    "        headings = self._get_text_by_category('heading1')\n",
    "        if headings:\n",
    "            first_heading = headings[0]['content']['text']\n",
    "            \n",
    "            # í•œêµ­ì–´ ì´ë ¥ì„œ: \"ì´ë ¥ì„œ - ML Engineer / ìµœì¬ê°•\" í˜•ì‹\n",
    "            if 'ì´ë ¥ì„œ' in first_heading or 'Resume' in first_heading:\n",
    "                # \"/\" ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬\n",
    "                if '/' in first_heading:\n",
    "                    parts = first_heading.split('/')\n",
    "                    if len(parts) >= 2:\n",
    "                        basic_info['name'] = parts[-1].strip()\n",
    "                        basic_info['title'] = parts[-2].split('-')[-1].strip() if '-' in parts[-2] else None\n",
    "            else:\n",
    "                # ì˜ì–´ ì´ë ¥ì„œ: ì´ë¦„ë§Œ ìˆëŠ” ê²½ìš°\n",
    "                basic_info['name'] = first_heading.strip()\n",
    "        \n",
    "        return basic_info\n",
    "    \n",
    "    def _extract_contact_info(self) -> Dict[str, Optional[str]]:\n",
    "        \"\"\"ì—°ë½ì²˜ ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "        contact_info = {\n",
    "            'email': None,\n",
    "            'phone': None,\n",
    "            'address': None,\n",
    "            'github': None,\n",
    "            'linkedin': None,\n",
    "            'blog': None,\n",
    "            'portfolio': None,\n",
    "        }\n",
    "        \n",
    "        # ëª¨ë“  í…ìŠ¤íŠ¸ë¥¼ ê²€ì‚¬\n",
    "        for elem in self.elements:\n",
    "            text = elem['content']['text']\n",
    "            \n",
    "            # ì´ë©”ì¼ ì¶”ì¶œ (ê³µë°±ì´ í¬í•¨ëœ ê²½ìš°ë„ ì²˜ë¦¬)\n",
    "            # \"jdrummond@cs Â· toronto . edu\" ê°™ì€ í˜•ì‹ ì²˜ë¦¬\n",
    "            email_pattern = r'[\\w\\.-]+@[\\w\\.-]+\\.\\w+'\n",
    "            email_match = re.search(email_pattern, text)\n",
    "            if email_match and not contact_info['email']:\n",
    "                contact_info['email'] = email_match.group(0)\n",
    "            elif 'Email:' in text or '@' in text:\n",
    "                # ê³µë°±ì´ í¬í•¨ëœ ì´ë©”ì¼ ì²˜ë¦¬\n",
    "                cleaned_text = text.replace(' Â· ', '.').replace(' . ', '.').replace(' ', '')\n",
    "                email_match = re.search(email_pattern, cleaned_text)\n",
    "                if email_match and not contact_info['email']:\n",
    "                    contact_info['email'] = email_match.group(0)\n",
    "            \n",
    "            # ì „í™”ë²ˆí˜¸ ì¶”ì¶œ (í•œêµ­, êµ­ì œ í˜•ì‹)\n",
    "            phone_pattern = r'(\\d{3}[-\\s]?\\d{4}[-\\s]?\\d{4}|\\d{3}[-\\s]?\\d{3}[-\\s]?\\d{4})'\n",
    "            phone_match = re.search(phone_pattern, text)\n",
    "            if phone_match and not contact_info['phone']:\n",
    "                contact_info['phone'] = phone_match.group(0)\n",
    "            \n",
    "            # URL ì¶”ì¶œ\n",
    "            if 'github.com' in text.lower():\n",
    "                github_pattern = r'https?://github\\.com/[\\w-]+'\n",
    "                github_match = re.search(github_pattern, text)\n",
    "                if github_match:\n",
    "                    contact_info['github'] = github_match.group(0)\n",
    "            \n",
    "            if 'linkedin.com' in text.lower() or 'liinkedin.com' in text.lower():\n",
    "                linkedin_pattern = r'https?://(?:www\\.)?li+nkedin\\.com/in/[\\w-]+'\n",
    "                linkedin_match = re.search(linkedin_pattern, text)\n",
    "                if linkedin_match:\n",
    "                    contact_info['linkedin'] = linkedin_match.group(0)\n",
    "            \n",
    "            if 'tistory.com' in text.lower() or 'blog' in text.lower():\n",
    "                blog_pattern = r'https?://[\\w-]+\\.(?:tistory\\.com|blog\\.[\\w.]+)'\n",
    "                blog_match = re.search(blog_pattern, text)\n",
    "                if blog_match:\n",
    "                    contact_info['blog'] = blog_match.group(0)\n",
    "            \n",
    "            # ì£¼ì†Œ ì¶”ì¶œ (ì˜ì–´ ì´ë ¥ì„œ)\n",
    "            if 'Toronto' in text or 'Canada' in text or ('University' in text and 'Department' in text):\n",
    "                if not contact_info['address'] and len(text) > 20 and len(text.split('\\n')) > 2:\n",
    "                    contact_info['address'] = text\n",
    "        \n",
    "        return contact_info\n",
    "    \n",
    "    def _extract_introduction(self) -> Optional[str]:\n",
    "        \"\"\"ìê¸°ì†Œê°œ ì¶”ì¶œ\"\"\"\n",
    "        introduction = None\n",
    "        \n",
    "        # \"Introduction\" ì„¹ì…˜ ì°¾ê¸°\n",
    "        for i, elem in enumerate(self.elements):\n",
    "            if elem.get('category') == 'heading1' and 'Introduction' in elem['content']['text']:\n",
    "                # ë‹¤ìŒ ìš”ì†Œê°€ listë‚˜ paragraphë©´ ê·¸ê²ƒì´ ì†Œê°œê¸€\n",
    "                if i + 1 < len(self.elements):\n",
    "                    next_elem = self.elements[i + 1]\n",
    "                    if next_elem.get('category') in ['list', 'paragraph']:\n",
    "                        introduction = next_elem['content']['text']\n",
    "                        break\n",
    "        \n",
    "        return introduction\n",
    "    \n",
    "    def _extract_work_experiences(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"ê²½ë ¥ ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "        experiences = []\n",
    "        \n",
    "        # \"Experience\" ë˜ëŠ” \"Career\" ì„¹ì…˜ ì°¾ê¸°\n",
    "        in_experience_section = False\n",
    "        current_experience = None\n",
    "        current_project_name = None\n",
    "        \n",
    "        for i, elem in enumerate(self.elements):\n",
    "            text = elem['content']['text']\n",
    "            category = elem.get('category')\n",
    "            \n",
    "            # ì„¹ì…˜ ì‹œì‘ ê°ì§€ (Experience, Career, Research Experience, Teaching Experience)\n",
    "            if category == 'heading1':\n",
    "                # Experience ê´€ë ¨ ì„¹ì…˜ì¸ì§€ í™•ì¸\n",
    "                is_experience_section = (\n",
    "                    ('Experience' in text or 'Career' in text) and\n",
    "                    not any(exclude in text for exclude in ['Publication', 'Award'])\n",
    "                )\n",
    "                \n",
    "                if is_experience_section:\n",
    "                    in_experience_section = True\n",
    "                    continue\n",
    "            \n",
    "            # ë‹¤ë¥¸ ì£¼ìš” ì„¹ì…˜ ì‹œì‘ë˜ë©´ ì¢…ë£Œ (Education, Publications, Project ë“±)\n",
    "            if category == 'heading1' and in_experience_section:\n",
    "                if any(keyword in text for keyword in ['Education', 'Publication', 'Award', 'Working Papers', 'Project', 'Certification', 'Technical Skills']):\n",
    "                    # í˜„ì¬ ê²½ë ¥ ì €ì¥\n",
    "                    if current_experience:\n",
    "                        experiences.append(current_experience)\n",
    "                    in_experience_section = False\n",
    "                    current_experience = None\n",
    "                    current_project_name = None\n",
    "                # íšŒì‚¬ëª…/í”„ë¡œì íŠ¸ëŠ” ê³„ì† ì²˜ë¦¬\n",
    "                else:\n",
    "                    # íšŒì‚¬ëª…/ì§ì±…ì´ ìˆëŠ” heading1\n",
    "                    if 'I' in text or '|' in text or any(word in text.lower() for word in ['engineer', 'developer', 'manager']):\n",
    "                        if current_experience:\n",
    "                            experiences.append(current_experience)\n",
    "                        \n",
    "                        # íšŒì‚¬ëª…ê³¼ ì§ì±… ë¶„ë¦¬\n",
    "                        company = None\n",
    "                        position = None\n",
    "                        \n",
    "                        if 'I' in text:\n",
    "                            parts = text.split('I')\n",
    "                            if len(parts) >= 2:\n",
    "                                company = parts[0].strip()\n",
    "                                position = parts[1].strip()\n",
    "                        elif '|' in text:\n",
    "                            parts = text.split('|')\n",
    "                            if len(parts) >= 2:\n",
    "                                company = parts[0].strip()\n",
    "                                position = parts[1].strip()\n",
    "                        else:\n",
    "                            # ì „ì²´ë¥¼ íšŒì‚¬ëª…ìœ¼ë¡œ\n",
    "                            company = text.strip()\n",
    "                        \n",
    "                        current_experience = {\n",
    "                            'company_name': company,\n",
    "                            'position': position,\n",
    "                            'start_date': None,\n",
    "                            'end_date': None,\n",
    "                            'description': '',\n",
    "                            'achievements': '',\n",
    "                            'projects': [],\n",
    "                        }\n",
    "                        current_project_name = None\n",
    "                    # í”„ë¡œì íŠ¸ ì´ë¦„ì¸ ê²½ìš° (íšŒì‚¬ ë‚´ í”„ë¡œì íŠ¸)\n",
    "                    elif current_experience:\n",
    "                        # heading1 ë˜ëŠ” paragraph ì¤‘ í”„ë¡œì íŠ¸ í‚¤ì›Œë“œ ìˆëŠ” ê²½ìš°  \n",
    "                        is_project_title = (\n",
    "                            (len(text) < 100) and  \n",
    "                            ('ê°œë°œ' in text or 'í”„ë¡œì íŠ¸' in text or 'ì±—ë´‡' in text or 'QA' in text or \n",
    "                             'POC' in text or 'êµ¬í˜„' in text or 'ìµœì í™”' in text) and\n",
    "                            # ì„±ê³¼ë‚˜ ì—…ë¬´ ì„¤ëª… ì•„ë‹Œ ê²ƒ\n",
    "                            not ('ì„±ê³¼' in text or 'ë‹¬ì„±' in text or 'í–¥ìƒ' in text or 'ì¦ê°€' in text)\n",
    "                        )\n",
    "                        \n",
    "                        if is_project_title:\n",
    "                            current_project_name = text.strip()\n",
    "                            current_experience['projects'].append({\n",
    "                                'name': current_project_name,\n",
    "                                'description': '',\n",
    "                            })\n",
    "            \n",
    "            if in_experience_section:\n",
    "                # ë¨¼ì € paragraphê°€ í”„ë¡œì íŠ¸ ì œëª©ì¸ì§€ í™•ì¸\n",
    "                if category == 'paragraph' and current_experience:\n",
    "                    # ì›ë³¸ í…ìŠ¤íŠ¸ì—ì„œ bullet point ì²´í¬ (strip ì „)\n",
    "                    stripped = text.strip()\n",
    "                    is_project_title = (\n",
    "                        (len(text) < 100) and\n",
    "                        # í”„ë¡œì íŠ¸ ê´€ë ¨ í‚¤ì›Œë“œ (í•œêµ­ì–´ + ì˜ì–´)\n",
    "                        ('ê°œë°œ' in text or 'í”„ë¡œì íŠ¸' in text or 'project' in text.lower() or\n",
    "                         'ì±—ë´‡' in text or 'chatbot' in text.lower() or\n",
    "                         'QA í™ˆí˜ì´ì§€' in text or 'POC' in text or 'LogitProcessor êµ¬í˜„' in text or\n",
    "                         'development' in text.lower() or 'system' in text.lower()) and\n",
    "                        # ì œì™¸í•  íŒ¨í„´ë“¤ (í•œêµ­ì–´ + ì˜ì–´)\n",
    "                        not ('ì„±ê³¼' in text or 'achievement' in text.lower() or\n",
    "                             'ë‹¬ì„±' in text or 'í–¥ìƒ' in text or 'ì¦ê°€' in text or\n",
    "                             'ê¸°ì¡´' in text or 'ëª©í‘œ' in text or 'ëª¨ë¸' in text or \n",
    "                             stripped.startswith('Â·') or stripped.startswith('ã€‚') or stripped.startswith('-') or\n",
    "                             'ìµœì í™”' == stripped or 'ê³ ë„í™”' in text or\n",
    "                             'ì ìˆ˜' in text or 'ì§„í–‰' in text or 'ìˆ˜ì£¼' in text)\n",
    "                    )\n",
    "                    \n",
    "                    if is_project_title:\n",
    "                        current_project_name = text.strip()\n",
    "                        current_experience['projects'].append({\n",
    "                            'name': current_project_name,\n",
    "                            'description': '',\n",
    "                        })\n",
    "                        continue  # ë‹¤ìŒ elementë¡œ\n",
    "                \n",
    "                # Research Experience ì„¹ì…˜ì˜ paragraph í˜•ì‹ ê²½ë ¥ ì •ë³´ íŒŒì‹± (ì˜ì–´ ì´ë ¥ì„œ)\n",
    "                # í•œêµ­ì–´ ë‚ ì§œ íŒŒì‹± ì „ì— ë¨¼ì € ì²´í¬\n",
    "                if category == 'paragraph' and in_experience_section:\n",
    "                    # ì˜ì–´ ë‚ ì§œ íŒ¨í„´ (May 2016 to August 2016)\n",
    "                    date_pattern_en = r'(January|February|March|April|May|June|July|August|September|October|November|December|Spring|Fall)\\s+(\\d{4})\\s+to\\s+(Present|(January|February|March|April|May|June|July|August|September|October|November|December|Spring|Fall)\\s+(\\d{4}))'\n",
    "                    date_match_en = re.search(date_pattern_en, text)\n",
    "                    \n",
    "                    # ì§ì±… íŒ¨í„´\n",
    "                    position_patterns = [\n",
    "                        r'^(Research (?:Intern|Assistant|Associate|Fellow|Scientist))',\n",
    "                        r'^(Teaching Assistant|Teaching Fellow)',\n",
    "                        r'^(Directed Study)',\n",
    "                    ]\n",
    "                    \n",
    "                    position_match = None\n",
    "                    for pattern in position_patterns:\n",
    "                        position_match = re.search(pattern, text)\n",
    "                        if position_match:\n",
    "                            break\n",
    "                    \n",
    "                    # ìƒˆë¡œìš´ ê²½ë ¥ (ì§ì±… + ë‚ ì§œ)\n",
    "                    if position_match and date_match_en:\n",
    "                        if current_experience:\n",
    "                            experiences.append(current_experience)\n",
    "                        \n",
    "                        position = position_match.group(1)\n",
    "                        \n",
    "                        # ì¡°ì§ëª… ì¶”ì¶œ\n",
    "                        company = None\n",
    "                        parts = text.split(',')\n",
    "                        if len(parts) >= 2:\n",
    "                            company = parts[1].strip()\n",
    "                            if ' with ' in company:\n",
    "                                company = company.split(' with ')[0].strip()\n",
    "                        \n",
    "                        # ë‚ ì§œ íŒŒì‹±\n",
    "                        start_date = f\"{date_match_en.group(1)} {date_match_en.group(2)}\"\n",
    "                        end_str = date_match_en.group(3)\n",
    "                        end_date = \"Present\" if \"Present\" in end_str else end_str\n",
    "                        \n",
    "                        current_experience = {\n",
    "                            'company_name': company,\n",
    "                            'position': position,\n",
    "                            'start_date': start_date,\n",
    "                            'end_date': end_date,\n",
    "                            'description': '',\n",
    "                            'achievements': '',\n",
    "                            'projects': [],\n",
    "                        }\n",
    "                        current_project_name = None\n",
    "                        continue\n",
    "                \n",
    "                # ë‚ ì§œ ì •ë³´ ì¶”ì¶œ (ì˜¤ë¥¸ìª½ì— ìœ„ì¹˜í•œ ë‚ ì§œë§Œ - x > 0.5, í•œêµ­ì–´ í˜•ì‹)\n",
    "                if category == 'paragraph' and re.search(r'\\d{4}', text):\n",
    "                    # \"2023.08 - Present\" ë˜ëŠ” \"2023.08 - í˜„ì¬\" í˜•ì‹\n",
    "                    date_pattern = r'(\\d{4}\\.\\d{2}|\\d{4})[\\s-]+(Present|present|í˜„ì¬|\\d{4}\\.\\d{2}|\\d{4})'\n",
    "                    date_match = re.search(date_pattern, text)\n",
    "                    # ë‚ ì§œê°€ ì˜¤ë¥¸ìª½ì— ìœ„ì¹˜í•˜ëŠ”ì§€ í™•ì¸ (xì¢Œí‘œ > 0.5)\n",
    "                    coords = elem.get('coordinates', [])\n",
    "                    is_right_aligned = coords and len(coords) > 0 and coords[0].get('x', 0) > 0.5\n",
    "                    \n",
    "                    if date_match and current_experience and is_right_aligned:\n",
    "                        current_experience['start_date'] = date_match.group(1)\n",
    "                        end = date_match.group(2)\n",
    "                        current_experience['end_date'] = None if end.lower() in ['present', 'í˜„ì¬'] else end\n",
    "                \n",
    "                # ì—…ë¬´ ë‚´ìš©ì´ë‚˜ ì„±ê³¼\n",
    "                elif category in ['paragraph', 'list']:\n",
    "                    content = text.strip()\n",
    "                    \n",
    "                    # Research Experience ì„¹ì…˜ì˜ paragraph í˜•ì‹ ê²½ë ¥ ì •ë³´ íŒŒì‹±\n",
    "                    # ì˜ˆ: \"Research Intern, Microsoft Research, with Ian Kash and Peter Key, May 2016 to August 2016.\"\n",
    "                    if category == 'paragraph' and in_experience_section:\n",
    "                        # ë‚ ì§œ íŒ¨í„´ í™•ì¸ (May 2016 to August 2016 í˜•ì‹)\n",
    "                        date_pattern = r'(January|February|March|April|May|June|July|August|September|October|November|December|Spring|Fall)\\s+(\\d{4})\\s+to\\s+(Present|(January|February|March|April|May|June|July|August|September|October|November|December|Spring|Fall)\\s+(\\d{4}))'\n",
    "                        date_match = re.search(date_pattern, text)\n",
    "                        \n",
    "                        # ì§ì±… íŒ¨í„´ (Research Intern, Research Assistant, etc.)\n",
    "                        position_patterns = [\n",
    "                            r'^(Research (?:Intern|Assistant|Associate|Fellow|Scientist))',\n",
    "                            r'^(Teaching Assistant|Teaching Fellow)',\n",
    "                            r'^((?:Graduate|Undergraduate) Research Assistant)',\n",
    "                            r'^((?:Postdoctoral|Post-doctoral) (?:Researcher|Fellow))',\n",
    "                        ]\n",
    "                        \n",
    "                        position_match = None\n",
    "                        for pattern in position_patterns:\n",
    "                            position_match = re.search(pattern, text)\n",
    "                            if position_match:\n",
    "                                break\n",
    "                        \n",
    "                        # ìƒˆë¡œìš´ ê²½ë ¥ í•­ëª©ì¸ ê²½ìš° (ì§ì±…ê³¼ ë‚ ì§œê°€ ìˆìŒ)\n",
    "                        if position_match and date_match:\n",
    "                            # ì´ì „ ê²½ë ¥ ì €ì¥\n",
    "                            if current_experience:\n",
    "                                experiences.append(current_experience)\n",
    "                            \n",
    "                            position = position_match.group(1)\n",
    "                            \n",
    "                            # ì¡°ì§ëª… ì¶”ì¶œ (ì§ì±… ë‹¤ìŒ ì½¤ë§ˆë¡œ êµ¬ë¶„)\n",
    "                            company = None\n",
    "                            parts = text.split(',')\n",
    "                            if len(parts) >= 2:\n",
    "                                company = parts[1].strip()\n",
    "                                # \"with\" ì´í›„ëŠ” ë©˜í† /ì§€ë„êµìˆ˜ì´ë¯€ë¡œ ì œì™¸\n",
    "                                if ' with ' in company:\n",
    "                                    company = company.split(' with ')[0].strip()\n",
    "                            \n",
    "                            # ë‚ ì§œ íŒŒì‹±\n",
    "                            start_month = date_match.group(1)\n",
    "                            start_year = date_match.group(2)\n",
    "                            end_str = date_match.group(3)\n",
    "                            \n",
    "                            start_date = f\"{start_month} {start_year}\"\n",
    "                            end_date = \"Present\" if \"Present\" in end_str else end_str\n",
    "                            \n",
    "                            current_experience = {\n",
    "                                'company_name': company,\n",
    "                                'position': position,\n",
    "                                'start_date': start_date,\n",
    "                                'end_date': end_date,\n",
    "                                'description': '',\n",
    "                                'achievements': '',\n",
    "                                'projects': [],\n",
    "                            }\n",
    "                            current_project_name = None\n",
    "                            continue\n",
    "                    \n",
    "                    # ì„±ê³¼ ì„¹ì…˜ (í•œêµ­ì–´ + ì˜ì–´)\n",
    "                    if 'ì„±ê³¼' in text or 'achievement' in text.lower() or 'accomplishment' in text.lower():\n",
    "                        if current_experience and len(content) <20:\n",
    "                            # ì„±ê³¼ ì œëª©ë§Œ ìˆìŒ\n",
    "                            pass\n",
    "                        elif current_experience:\n",
    "                            current_experience['achievements'] += content + '\\n'\n",
    "                    # í”„ë¡œì íŠ¸ ì„¤ëª…\n",
    "                    elif current_project_name and current_experience and len(current_experience['projects']) > 0:\n",
    "                        current_experience['projects'][-1]['description'] += content + '\\n'\n",
    "                    \n",
    "                    # ì¼ë°˜ ì—…ë¬´ ë‚´ìš©\n",
    "                    elif current_experience:\n",
    "                        # ë„ˆë¬´ ì§§ì€ ì œëª©ì€ ì œì™¸\n",
    "                        if len(content) > 10:\n",
    "                            current_experience['description'] += content + '\\n'\n",
    "        \n",
    "        # ë§ˆì§€ë§‰ ê²½ë ¥ ì €ì¥\n",
    "        if current_experience:\n",
    "            experiences.append(current_experience)\n",
    "        \n",
    "        return experiences\n",
    "    \n",
    "    def _extract_education(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"í•™ë ¥ ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "        education_list = []\n",
    "        \n",
    "        in_education_section = False\n",
    "        current_education = None\n",
    "        \n",
    "        for i, elem in enumerate(self.elements):\n",
    "            text = elem['content']['text']\n",
    "            category = elem.get('category')\n",
    "            \n",
    "            # Education ì„¹ì…˜ ì‹œì‘\n",
    "            if category == 'heading1' and 'Education' in text:\n",
    "                in_education_section = True\n",
    "                continue\n",
    "            \n",
    "            # ë‹¤ë¥¸ ì„¹ì…˜ ì‹œì‘ë˜ë©´ ì¢…ë£Œ\n",
    "            if category == 'heading1' and in_education_section and 'Education' not in text:\n",
    "                if current_education:\n",
    "                    education_list.append(current_education)\n",
    "                in_education_section = False\n",
    "                current_education = None\n",
    "            \n",
    "            if in_education_section:\n",
    "                # í•™ìœ„ ì •ë³´ íŒŒì‹±\n",
    "                if category == 'paragraph':\n",
    "                    # \"PhD Computer Science, University of Toronto, (expected) Spring 2017.\" í˜•ì‹\n",
    "                    # \"êµ­ë¯¼ëŒ€í•™êµ ì»´í“¨í„°ê³µí•™ê³¼ ì„ì‚¬\" í˜•ì‹\n",
    "                    \n",
    "                    degree_match = re.search(r'(PhD|M\\.S\\.|B\\.S\\.|ì„ì‚¬|í•™ì‚¬|ë°•ì‚¬)', text)\n",
    "                    if degree_match:\n",
    "                        if current_education:\n",
    "                            education_list.append(current_education)\n",
    "                        \n",
    "                        degree = degree_match.group(1)\n",
    "                        institution = None\n",
    "                        major = None\n",
    "                        start_date = None\n",
    "                        end_date = None\n",
    "                        \n",
    "                        # ëŒ€í•™ëª… ì¶”ì¶œ\n",
    "                        if 'University' in text:\n",
    "                            uni_match = re.search(r'(University of [\\w\\s]+|[\\w\\s]+University)', text)\n",
    "                            if uni_match:\n",
    "                                institution = uni_match.group(1).strip(',').strip()\n",
    "                        elif 'ëŒ€í•™êµ' in text:\n",
    "                            uni_match = re.search(r'([\\w]+ëŒ€í•™êµ)', text)\n",
    "                            if uni_match:\n",
    "                                institution = uni_match.group(1)\n",
    "                        \n",
    "                        # ì „ê³µ ì¶”ì¶œ\n",
    "                        if 'Computer Science' in text:\n",
    "                            major = 'Computer Science'\n",
    "                        elif 'Mathematics' in text:\n",
    "                            major = 'Mathematics'\n",
    "                        elif 'ì»´í“¨í„°ê³µí•™' in text:\n",
    "                            major = 'ì»´í“¨í„°ê³µí•™'\n",
    "                        elif 'ì†Œí”„íŠ¸ì›¨ì–´' in text:\n",
    "                            major = 'ì†Œí”„íŠ¸ì›¨ì–´'\n",
    "                        \n",
    "                        # ë‚ ì§œ ì¶”ì¶œ\n",
    "                        date_pattern = r'(Spring|Fall|December|Spring)?\\s*(\\d{4})'\n",
    "                        dates = re.findall(date_pattern, text)\n",
    "                        if dates:\n",
    "                            if len(dates) >= 1:\n",
    "                                end_date = dates[-1][1] if dates[-1][1] else dates[-1][0]\n",
    "                        \n",
    "                        current_education = {\n",
    "                            'institution': institution,\n",
    "                            'degree': degree,\n",
    "                            'major': major,\n",
    "                            'minor': None,\n",
    "                            'start_date': start_date,\n",
    "                            'end_date': end_date,\n",
    "                            'gpa': None,\n",
    "                            'honors': '',\n",
    "                            'relevant_courses': '',\n",
    "                        }\n",
    "                    \n",
    "                    # GPA ì¶”ì¶œ\n",
    "                    elif 'GPA' in text and current_education:\n",
    "                        gpa_match = re.search(r'GPA:\\s*([\\d.]+)', text)\n",
    "                        if gpa_match:\n",
    "                            current_education['gpa'] = gpa_match.group(1)\n",
    "                    \n",
    "                    # ìƒì„¸ ì •ë³´\n",
    "                    elif current_education:\n",
    "                        if 'Advisor' in text or 'Co-advisors' in text:\n",
    "                            current_education['honors'] += text + '\\n'\n",
    "                        elif 'Relevant Courses' in text or 'Courses' in text:\n",
    "                            current_education['relevant_courses'] += text + '\\n'\n",
    "                        elif 'Honors' in text or 'Dean' in text:\n",
    "                            current_education['honors'] += text + '\\n'\n",
    "                        elif 'Minor' in text:\n",
    "                            minor_match = re.search(r'Minor:\\s*([\\w\\s]+)', text)\n",
    "                            if minor_match:\n",
    "                                current_education['minor'] = minor_match.group(1).strip('.')\n",
    "        \n",
    "        # ë§ˆì§€ë§‰ í•™ë ¥ ì €ì¥\n",
    "        if current_education:\n",
    "            education_list.append(current_education)\n",
    "        \n",
    "        # Career ì„¹ì…˜ì˜ í•™ë ¥ ì •ë³´ë„ ì¶”ì¶œ (í•œêµ­ì–´ ì´ë ¥ì„œ)\n",
    "        for elem in self.elements:\n",
    "            text = elem['content']['text']\n",
    "            if elem.get('category') == 'list':\n",
    "                if 'ëŒ€í•™êµ' in text and ('ì„ì‚¬' in text or 'í•™ì‚¬' in text):\n",
    "                    parts = text.strip('Â· ').strip()\n",
    "                    \n",
    "                    # ì´ë¯¸ ì¶”ê°€ë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì¶”ê°€ (í•™ìœ„+ì „ê³µ ì¡°í•©ìœ¼ë¡œ ì¤‘ë³µ ì²´í¬)\n",
    "                    degree = 'ì„ì‚¬' if 'ì„ì‚¬' in parts else 'í•™ì‚¬'\n",
    "                    institution = re.search(r'([\\w]+ëŒ€í•™êµ)', parts)\n",
    "                    \n",
    "                    # ì „ê³µì„ ë” ì„¸ë°€í•˜ê²Œ ì¶”ì¶œ\n",
    "                    if 'ì†Œí”„íŠ¸ì›¨ì–´í•™ë¶€' in parts:\n",
    "                        major_text = 'ì†Œí”„íŠ¸ì›¨ì–´í•™ë¶€'\n",
    "                    elif 'ì»´í“¨í„°ê³µí•™ê³¼' in parts:\n",
    "                        major_text = 'ì»´í“¨í„°ê³µí•™ê³¼'\n",
    "                    elif 'ì†Œí”„íŠ¸ì›¨ì–´' in parts:\n",
    "                        major_text = 'ì†Œí”„íŠ¸ì›¨ì–´'\n",
    "                    elif 'ì»´í“¨í„°ê³µí•™' in parts:\n",
    "                        major_text = 'ì»´í“¨í„°ê³µí•™'\n",
    "                    else:\n",
    "                        major_text = None\n",
    "                    \n",
    "                    # ê°™ì€ í•™ìœ„+ì „ê³µ ì¡°í•©ì´ ì—†ìœ¼ë©´ ì¶”ê°€\n",
    "                    inst_name = institution.group(1) if institution else None\n",
    "                    is_duplicate = any(\n",
    "                        edu['institution'] == inst_name and \n",
    "                        edu['degree'] == degree and \n",
    "                        edu['major'] == major_text \n",
    "                        for edu in education_list\n",
    "                    )\n",
    "                    \n",
    "                    if not is_duplicate:\n",
    "                        education_list.append({\n",
    "                            'institution': inst_name,\n",
    "                            'degree': degree,\n",
    "                            'major': major_text,\n",
    "                            'minor': None,\n",
    "                            'start_date': None,\n",
    "                            'end_date': None,\n",
    "                            'gpa': None,\n",
    "                            'honors': '',\n",
    "                            'relevant_courses': '',\n",
    "                        })\n",
    "        \n",
    "        return education_list\n",
    "    \n",
    "    def _extract_projects(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"í”„ë¡œì íŠ¸ ì •ë³´ ì¶”ì¶œ (ë³„ë„ Project ì„¹ì…˜ì˜ ì™¸ë¶€ í”„ë¡œì íŠ¸)\"\"\"\n",
    "        projects = []\n",
    "        \n",
    "        in_project_section = False\n",
    "        current_project = None\n",
    "        \n",
    "        for elem in self.elements:\n",
    "            text = elem['content']['text']\n",
    "            category = elem.get('category')\n",
    "            \n",
    "            # Project ì„¹ì…˜ ì‹œì‘\n",
    "            if category == 'heading1' and text.strip() == 'Project':\n",
    "                in_project_section = True\n",
    "                continue\n",
    "            \n",
    "            # ë‹¤ë¥¸ ì£¼ìš” ì„¹ì…˜ ì‹œì‘ë˜ë©´ ì¢…ë£Œ\n",
    "            if category == 'heading1' and in_project_section:\n",
    "                if any(keyword in text for keyword in ['Certification', 'Award', 'Publication', 'Education']):\n",
    "                    if current_project:\n",
    "                        projects.append(current_project)\n",
    "                    in_project_section = False\n",
    "                    current_project = None\n",
    "                    continue\n",
    "                \n",
    "                # Project ì„¹ì…˜ ë‚´ì˜ í”„ë¡œì íŠ¸ ì œëª© (heading1)\n",
    "                # ì˜ˆ: \"ê°€ì§œì—°êµ¬ì†Œ ëŸ¬ë„ˆ í™œë™\", \"ê°œì¸ í”„ë¡œì íŠ¸\" ë“±\n",
    "                if current_project:\n",
    "                    projects.append(current_project)\n",
    "                \n",
    "                current_project = {\n",
    "                    'title': text.strip(),\n",
    "                    'description': '',\n",
    "                    'start_date': None,\n",
    "                    'end_date': None,\n",
    "                }\n",
    "            \n",
    "            # í”„ë¡œì íŠ¸ ì„¹ì…˜ ë‚´ì˜ ë‚´ìš©\n",
    "            elif in_project_section:\n",
    "                if category == 'paragraph':\n",
    "                    # ë‚ ì§œ íŒ¨í„´ í™•ì¸\n",
    "                    date_pattern = r'(\\d{4}\\.\\d{2})\\s*-\\s*(Present|í˜„ì¬)'\n",
    "                    date_match = re.search(date_pattern, text)\n",
    "                    if date_match and current_project:\n",
    "                        current_project['start_date'] = date_match.group(1)\n",
    "                        current_project['end_date'] = 'Present' if date_match.group(2) in ['Present', 'í˜„ì¬'] else None\n",
    "                    elif current_project:\n",
    "                        # í”„ë¡œì íŠ¸ ì œëª©ì¼ ìˆ˜ë„ (paragraphì¸ ê²½ìš°)\n",
    "                        if len(text) < 100 and len(current_project['description']) == 0:\n",
    "                            current_project['description'] += text + '\\n'\n",
    "                        else:\n",
    "                            current_project['description'] += text + '\\n'\n",
    "                elif category == 'list' and current_project:\n",
    "                    current_project['description'] += text + '\\n'\n",
    "        \n",
    "        if current_project:\n",
    "            projects.append(current_project)\n",
    "        \n",
    "        return projects\n",
    "    \n",
    "    def _extract_publications(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"ì¶œíŒë¬¼/ë…¼ë¬¸ ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "        publications = []\n",
    "        \n",
    "        in_publication_section = False\n",
    "        \n",
    "        for i, elem in enumerate(self.elements):\n",
    "            text = elem['content']['text']\n",
    "            category = elem.get('category')\n",
    "            \n",
    "            # Publications ì„¹ì…˜ ì‹œì‘\n",
    "            if category == 'heading1' and 'Publication' in text:\n",
    "                in_publication_section = True\n",
    "                continue\n",
    "            \n",
    "            # ë‹¤ë¥¸ ì„¹ì…˜ ì‹œì‘\n",
    "            if category == 'heading1' and in_publication_section:\n",
    "                if 'Publication' not in text and 'Working Papers' not in text:\n",
    "                    in_publication_section = False\n",
    "            \n",
    "            if in_publication_section and category == 'paragraph':\n",
    "                # ë…¼ë¬¸ ì œëª©, ì €ì, í•™íšŒ ì •ë³´ íŒŒì‹±\n",
    "                # \"Title, Authors, Venue (Conference), pages.\"\n",
    "                \n",
    "                # ì½¤ë§ˆë¡œ ë¶„ë¦¬\n",
    "                parts = text.split(',')\n",
    "                \n",
    "                if len(parts) >= 2:\n",
    "                    title = parts[0].strip()\n",
    "                    authors = parts[1].strip() if len(parts) > 1 else ''\n",
    "                    venue = ''\n",
    "                    year = None\n",
    "                    pages = None\n",
    "                    \n",
    "                    # Year ì¶”ì¶œ\n",
    "                    year_match = re.search(r'\\((\\d{4})\\)|\\s(\\d{4})', text)\n",
    "                    if year_match:\n",
    "                        year = year_match.group(1) or year_match.group(2)\n",
    "                    \n",
    "                    # Pages ì¶”ì¶œ\n",
    "                    pages_match = re.search(r'pages?\\s*([\\d-]+)', text)\n",
    "                    if pages_match:\n",
    "                        pages = pages_match.group(1)\n",
    "                    \n",
    "                    # Venue (Proc. of ...)\n",
    "                    venue_match = re.search(r'Proc\\. of[^,]+', text)\n",
    "                    if venue_match:\n",
    "                        venue = venue_match.group(0)\n",
    "                    \n",
    "                    publications.append({\n",
    "                        'title': title,\n",
    "                        'authors': authors,\n",
    "                        'venue': venue,\n",
    "                        'year': year,\n",
    "                        'pages': pages,\n",
    "                        'description': text,\n",
    "                    })\n",
    "        \n",
    "        return publications\n",
    "    \n",
    "    def _extract_skills_and_channels(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"ê¸°ìˆ /ì±„ë„ ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "        skills = []\n",
    "        \n",
    "        in_tech_section = False\n",
    "        \n",
    "        for i, elem in enumerate(self.elements):\n",
    "            text = elem['content']['text']\n",
    "            category = elem.get('category')\n",
    "            \n",
    "            # Technical Skills ì„¹ì…˜ ì‹œì‘\n",
    "            if category == 'heading1' and ('Technical Skills' in text or 'Skills' in text):\n",
    "                in_tech_section = True\n",
    "                continue\n",
    "            \n",
    "            # ë‹¤ë¥¸ ì„¹ì…˜ ì‹œì‘ë˜ë©´ ì¢…ë£Œ\n",
    "            if category == 'heading1' and in_tech_section:\n",
    "                in_tech_section = False\n",
    "            \n",
    "            # Technical Skills ì„¹ì…˜ ë‚´ìš© íŒŒì‹±\n",
    "            if in_tech_section and category == 'paragraph':\n",
    "                # ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬\n",
    "                lines = text.split('\\n')\n",
    "                for line in lines:\n",
    "                    line = line.strip()\n",
    "                    if not line:\n",
    "                        continue\n",
    "                    \n",
    "                    # \"Category: Details\" í˜•ì‹ íŒŒì‹±\n",
    "                    if ':' in line:\n",
    "                        parts = line.split(':', 1)\n",
    "                        if len(parts) == 2:\n",
    "                            category_name = parts[0].strip()\n",
    "                            details = parts[1].strip()\n",
    "                            skills.append({\n",
    "                                'category': 'technical_skill',\n",
    "                                'name': category_name,\n",
    "                                'value': details\n",
    "                            })\n",
    "            \n",
    "            # Channel ì„¹ì…˜\n",
    "            if category == 'heading1' and 'Channel' in text:\n",
    "                # ë‹¤ìŒ list í•­ëª©ë“¤ì´ ì±„ë„\n",
    "                idx = self.elements.index(elem)\n",
    "                if idx + 1 < len(self.elements):\n",
    "                    next_elem = self.elements[idx + 1]\n",
    "                    if next_elem.get('category') == 'list':\n",
    "                        lines = next_elem['content']['text'].split('\\n')\n",
    "                        for line in lines:\n",
    "                            if 'Github' in line:\n",
    "                                skills.append({'category': 'channel', 'name': 'Github', 'value': line.split('I')[-1].strip() if 'I' in line else line})\n",
    "                            elif 'Linkedin' in line or 'Linkedln' in line:\n",
    "                                skills.append({'category': 'channel', 'name': 'LinkedIn', 'value': line.split('I')[-1].strip() if 'I' in line else line})\n",
    "                            elif 'Blog' in line:\n",
    "                                skills.append({'category': 'channel', 'name': 'Blog', 'value': line.split('I')[-1].strip() if 'I' in line else line})\n",
    "        \n",
    "        return skills\n",
    "    \n",
    "    def _extract_certificates(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"ìê²©ì¦ ì •ë³´ ì¶”ì¶œ\"\"\"\n",
    "        certificates = []\n",
    "        \n",
    "        in_cert_section = False\n",
    "        \n",
    "        for elem in self.elements:\n",
    "            text = elem['content']['text']\n",
    "            category = elem.get('category')\n",
    "            \n",
    "            # Certification ì„¹ì…˜ ì‹œì‘\n",
    "            if category == 'heading1' and 'Certification' in text:\n",
    "                in_cert_section = True\n",
    "                continue\n",
    "            \n",
    "            # ë‹¤ë¥¸ ì„¹ì…˜ ì‹œì‘ë˜ë©´ ì¢…ë£Œ\n",
    "            if category == 'heading1' and in_cert_section:\n",
    "                in_cert_section = False\n",
    "            \n",
    "            # Certification ì„¹ì…˜ ë‚´ì˜ ìê²©ì¦\n",
    "            if in_cert_section and category == 'list':\n",
    "                # ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬ëœ ìê²©ì¦ë“¤\n",
    "                lines = text.split('\\n')\n",
    "                for line in lines:\n",
    "                    line = line.strip().strip('Â·').strip()\n",
    "                    if line and len(line) > 2:\n",
    "                        certificates.append({\n",
    "                            'name': line,\n",
    "                            'issuer': None,\n",
    "                            'date': None,\n",
    "                        })\n",
    "        \n",
    "        return certificates\n",
    "    \n",
    "    def _extract_awards(self) -> List[Dict[str, Any]]:\n",
    "        \"\"\"ìˆ˜ìƒ ì´ë ¥ ì¶”ì¶œ\"\"\"\n",
    "        awards = []\n",
    "        \n",
    "        in_award_section = False\n",
    "        \n",
    "        for elem in self.elements:\n",
    "            text = elem['content']['text']\n",
    "            category = elem.get('category')\n",
    "            \n",
    "            # Award ì„¹ì…˜ ì‹œì‘\n",
    "            if category == 'heading1' and 'Award' in text:\n",
    "                in_award_section = True\n",
    "                continue\n",
    "            \n",
    "            # ë‹¤ë¥¸ ì„¹ì…˜ ì‹œì‘ë˜ë©´ ì¢…ë£Œ\n",
    "            if category == 'heading1' and in_award_section:\n",
    "                in_award_section = False\n",
    "            \n",
    "            # Award ì„¹ì…˜ ë‚´ì˜ ìˆ˜ìƒ ë‚´ì—­\n",
    "            if in_award_section and category in ['list', 'paragraph']:\n",
    "                # ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¶„ë¦¬ëœ ìˆ˜ìƒ ë‚´ì—­ë“¤\n",
    "                lines = text.split('\\n')\n",
    "                for line in lines:\n",
    "                    line = line.strip().strip('Â·').strip()\n",
    "                    if line and len(line) > 2:\n",
    "                        awards.append({\n",
    "                            'name': line,\n",
    "                            'issuer': None,\n",
    "                            'date': None,\n",
    "                        })\n",
    "        \n",
    "        return awards"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. ì¶œë ¥ í•¨ìˆ˜ ì •ì˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_parsed_resume(parsed_data: Dict[str, Any], title: str = \"Parsed Resume\"):\n",
    "    \"\"\"íŒŒì‹±ëœ ì´ë ¥ì„œ ì •ë³´ë¥¼ ë³´ê¸° ì¢‹ê²Œ ì¶œë ¥\"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\" {title}\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # ê¸°ë³¸ ì •ë³´\n",
    "    print(\"\\nğŸ“‹ ê¸°ë³¸ ì •ë³´:\")\n",
    "    basic = parsed_data.get('basic_info', {})\n",
    "    for key, value in basic.items():\n",
    "        if value:\n",
    "            print(f\"  â€¢ {key}: {value}\")\n",
    "    \n",
    "    # ì—°ë½ì²˜ ì •ë³´\n",
    "    print(\"\\nğŸ“ ì—°ë½ì²˜ ì •ë³´:\")\n",
    "    contact = parsed_data.get('contact_info', {})\n",
    "    for key, value in contact.items():\n",
    "        if value:\n",
    "            if key == 'address':\n",
    "                print(f\"  â€¢ {key}:\")\n",
    "                for line in value.split('\\n'):\n",
    "                    if line.strip():\n",
    "                        print(f\"      {line.strip()}\")\n",
    "            else:\n",
    "                print(f\"  â€¢ {key}: {value}\")\n",
    "    \n",
    "    # ìê¸°ì†Œê°œ\n",
    "    intro = parsed_data.get('introduction')\n",
    "    if intro:\n",
    "        print(\"\\nğŸ’¬ ìê¸°ì†Œê°œ:\")\n",
    "        for line in intro.split('\\n'):\n",
    "            if line.strip():\n",
    "                print(f\"  {line.strip()}\")\n",
    "    \n",
    "    # ê²½ë ¥\n",
    "    experiences = parsed_data.get('work_experiences', [])\n",
    "    if experiences:\n",
    "        print(f\"\\nğŸ’¼ ê²½ë ¥ ({len(experiences)}ê°œ):\")\n",
    "        for i, exp in enumerate(experiences, 1):\n",
    "            print(f\" \\n  [{i}] {exp.get('company_name', 'N/A')}\")\n",
    "            if exp.get('position'):\n",
    "                print(f\"      ì§ì±…: {exp['position']}\")\n",
    "            if exp.get('start_date') or exp.get('end_date'):\n",
    "                period = f\"{exp.get('start_date', '')} ~ {exp.get('end_date') or 'í˜„ì¬'}\"\n",
    "                print(f\"      ê¸°ê°„: {period}\")\n",
    "            if exp.get('description'):\n",
    "                desc_lines = [line for line in exp['description'].strip().split('\\n') if line.strip()]\n",
    "                if desc_lines:\n",
    "                    print(f\"      ì—…ë¬´ ë‚´ìš©:\")\n",
    "                    for line in desc_lines[:5]:\n",
    "                        cleaned = line.strip()\n",
    "                        if cleaned:\n",
    "                            print(f\"        - {cleaned[:120]}\")\n",
    "            if exp.get('projects'):\n",
    "                print(f\"      í”„ë¡œì íŠ¸ ({len(exp['projects'])}ê°œ):\")\n",
    "                for j, proj in enumerate(exp['projects'], 1):\n",
    "                    print(f\"        [{j}] {proj.get('name', 'N/A')}\")\n",
    "                    proj_desc = proj.get('description', '').strip()\n",
    "                    if proj_desc:\n",
    "                        proj_lines = [line for line in proj_desc.split('\\n') if line.strip()][:3]\n",
    "                        for line in proj_lines:\n",
    "                            print(f\"            - {line.strip()[:100]}\")\n",
    "            if exp.get('achievements'):\n",
    "                ach_lines = [line for line in exp['achievements'].strip().split('\\n') if line.strip()]\n",
    "                if ach_lines:\n",
    "                    print(f\"      ì„±ê³¼:\")\n",
    "                    for line in ach_lines[:3]:\n",
    "                        cleaned = line.strip()\n",
    "                        if cleaned:\n",
    "                            print(f\"        - {cleaned[:120]}\")\n",
    "    \n",
    "    # í•™ë ¥\n",
    "    education = parsed_data.get('education', [])\n",
    "    if education:\n",
    "        print(f\"\\nğŸ“ í•™ë ¥ ({len(education)}ê°œ):\")\n",
    "        for i, edu in enumerate(education, 1):\n",
    "            print(f\"\\n  [{i}] {edu.get('institution', 'N/A')}\")\n",
    "            if edu.get('degree'):\n",
    "                print(f\"      í•™ìœ„: {edu['degree']}\")\n",
    "            if edu.get('major'):\n",
    "                print(f\"      ì „ê³µ: {edu['major']}\")\n",
    "            if edu.get('gpa'):\n",
    "                print(f\"      GPA: {edu['gpa']}\")\n",
    "            if edu.get('end_date'):\n",
    "                print(f\"      ì¡¸ì—…: {edu['end_date']}\")\n",
    "    \n",
    "    # ì¶œíŒë¬¼\n",
    "    publications = parsed_data.get('publications', [])\n",
    "    if publications:\n",
    "        print(f\"\\nğŸ“š ì¶œíŒë¬¼ ({len(publications)}ê°œ):\")\n",
    "        for i, pub in enumerate(publications, 1):\n",
    "            print(f\"\\n  [{i}] {pub.get('title', 'N/A')}\")\n",
    "            if pub.get('authors'):\n",
    "                print(f\"      ì €ì: {pub['authors'][:80]}\")\n",
    "            if pub.get('venue'):\n",
    "                print(f\"      í•™íšŒ: {pub['venue'][:80]}\")\n",
    "            if pub.get('year'):\n",
    "                print(f\"      ì—°ë„: {pub['year']}\")\n",
    "    \n",
    "    # ì±„ë„/ìŠ¤í‚¬\n",
    "    skills = parsed_data.get('skills_and_channels', [])\n",
    "    if skills:\n",
    "        print(f\"\\nğŸ”— ì±„ë„ ë° ê¸°ìˆ  ({len(skills)}ê°œ):\")\n",
    "        for skill in skills:\n",
    "            print(f\"  â€¢ {skill.get('name', 'N/A')}: {skill.get('value', '')[:60]}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80 + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. ì´ë ¥ì„œ íŒŒì‹± ì‹¤í–‰"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-1. í•œêµ­ì–´ ì´ë ¥ì„œ íŒŒì‹± (cv_data00.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# í•œêµ­ì–´ ì´ë ¥ì„œ íŒŒì‹±\n",
    "parser_kr = ResumeParser('cv_data00.json')\n",
    "result_kr = parser_kr.parse()\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print_parsed_resume(result_kr, \"í•œêµ­ì–´ ì´ë ¥ì„œ (cv_data00.json)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4-2. ì˜ì–´ ì´ë ¥ì„œ íŒŒì‹± (cv_data01.json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      " ì˜ì–´ ì´ë ¥ì„œ (cv_data01.json)\n",
      "================================================================================\n",
      "\n",
      "ğŸ“‹ ê¸°ë³¸ ì •ë³´:\n",
      "  â€¢ name: Joanna Drummond\n",
      "\n",
      "ğŸ“ ì—°ë½ì²˜ ì •ë³´:\n",
      "  â€¢ email: jdrummond@cs.toronto.edu\n",
      "  â€¢ address:\n",
      "      Department of Computer Science\n",
      "      University of Toronto\n",
      "      10 King's College Road, Rm. 3302\n",
      "      Toronto, Ontario, M5S 3G4 Canada\n",
      "\n",
      "ğŸ’¼ ê²½ë ¥ (6ê°œ):\n",
      " \n",
      "  [1] Microsoft Research\n",
      "      ì§ì±…: Research Intern\n",
      "      ê¸°ê°„: May 2016 ~ August 2016\n",
      "      ì—…ë¬´ ë‚´ìš©:\n",
      "        - Investigated simple pricing for cloud computing.\n",
      " \n",
      "  [2] University of Toronto\n",
      "      ì§ì±…: Research Assistant\n",
      "      ê¸°ê°„: August 2011 ~ December 2014\n",
      "      ì—…ë¬´ ë‚´ìš©:\n",
      "        - Investigating Bayes-Nash and ex-post equilibria for matching games with imperfect information.\n",
      "        - Investigating stable and approximately stable matching using multi-attribute preference information.\n",
      "        - Investigating elicitation schemes using multi-attribute based queries.\n",
      "        - Investigating stable and approximately stable matching on social networks.\n",
      "        - Investigated elicitation schemes for the stable matching problem, including a scheme that found low\n",
      " \n",
      "  [3] University of Pittsburgh Department of Computer Science\n",
      "      ì§ì±…: Research Assistant\n",
      "      ê¸°ê°„: April 2008 ~ June 2010\n",
      "      ì—…ë¬´ ë‚´ìš©:\n",
      "        - Investigated the impact of different training set populations on accurately classifying student uncer-\n",
      "        - tainty while using a spoken intelligent physics tutor.\n",
      "        - Investigated applying the zoning out feature set to disengagement while using a spoken intelligent\n",
      "        - physics tutor.\n",
      "        - Designed a feature set for and applied decision trees to classifying student zoning out while performing\n",
      " \n",
      "  [4] University of Pittsburgh Department of Computer Science\n",
      "      ì§ì±…: Directed Study\n",
      "      ê¸°ê°„: September 2010 ~ December 2010\n",
      "      ì—…ë¬´ ë‚´ìš©:\n",
      "        - Analyzed and proved properties about an algorithm for dividing n indivisible objects among 2 people.\n",
      " \n",
      "  [5] DREU Program\n",
      "      ì§ì±…: Research Assistant\n",
      "      ê¸°ê°„: June 2010 ~ August 2010\n",
      "      ì—…ë¬´ ë‚´ìš©:\n",
      "        - Applied HMM's and decision trees to students' online forum data to categorize students' posts.\n",
      "        - Performed a corpus study to analyze correlations between speech acts and thread length in students'\n",
      "        - online forum data.\n",
      "        - Annotated students' online forum data.\n",
      " \n",
      "  [6] University of Toronto Dept. of Computer Science\n",
      "      ì§ì±…: Teaching Assistant\n",
      "      ê¸°ê°„: September 2011 ~ Present\n",
      "\n",
      "ğŸ“ í•™ë ¥ (3ê°œ):\n",
      "\n",
      "  [1] University\n",
      "      í•™ìœ„: PhD\n",
      "      ì „ê³µ: Computer Science\n",
      "      GPA: 3.83\n",
      "      ì¡¸ì—…: 2017\n",
      "\n",
      "  [2] University\n",
      "      í•™ìœ„: M.S.\n",
      "      ì „ê³µ: Computer Science\n",
      "      GPA: 3.93\n",
      "      ì¡¸ì—…: 2013\n",
      "\n",
      "  [3] University\n",
      "      í•™ìœ„: B.S.\n",
      "      ì „ê³µ: Computer Science\n",
      "      GPA: 3.73\n",
      "      ì¡¸ì—…: 2010\n",
      "\n",
      "ğŸ“š ì¶œíŒë¬¼ (3ê°œ):\n",
      "\n",
      "  [1] Strategy-Proofness in the Stable Matching Problem with Couples\n",
      "      ì €ì: Perrault\n",
      "      í•™íšŒ: Proc. of the Fifteenth International Conference on Autonomous Agents and Multiag\n",
      "      ì—°ë„: 2016\n",
      "\n",
      "  [2] SAT is an Effective and Complete Method for Solving Stable Matching Problems with Couples\n",
      "      ì €ì: Drum-\n",
      "mond\n",
      "      í•™íšŒ: Proc. of the Twenty-fourth International Joint Conference on\n",
      "Artificial Intellig\n",
      "\n",
      "  [3] Preference Elicitation and Interview Minimization in Stable Matchings\n",
      "      ì €ì: Drummond\n",
      "      í•™íšŒ: Proc. of the Twenty-eighth Conference on Artificial Intelligence (AAAI-14)\n",
      "\n",
      "ğŸ”— ì±„ë„ ë° ê¸°ìˆ  (3ê°œ):\n",
      "  â€¢ Programming Languages: Proficient: Python, Java; Familiar: Julia, R, Matlab, Unix S\n",
      "  â€¢ Operating Systems: Proficient: Linux, Mac OSX; Familiar: Windows\n",
      "  â€¢ Other Skills: IATEX, Weka\n",
      "\n",
      "================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ì˜ì–´ ì´ë ¥ì„œ íŒŒì‹±\n",
    "parser_en = ResumeParser('cv_data01.json')\n",
    "result_en = parser_en.parse()\n",
    "\n",
    "# ê²°ê³¼ ì¶œë ¥\n",
    "print_parsed_resume(result_en, \"ì˜ì–´ ì´ë ¥ì„œ (cv_data01.json)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. íŒŒì‹± ê²°ê³¼ ìš”ì•½"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "  ğŸ“Š íŒŒì‹± ìš”ì•½\n",
      "================================================================================\n",
      "\n",
      "cv_data00.json (í•œêµ­ì–´):\n",
      "  - ì´ë¦„: ìµœì¬ê°•\n",
      "  - ì´ë©”ì¼: workd.official@gmail.com\n",
      "  - ì „í™”ë²ˆí˜¸: 010-9040-6282\n",
      "  - ê²½ë ¥: 1ê°œ\n",
      "  - í•™ë ¥: 2ê°œ\n",
      "  - í”„ë¡œì íŠ¸: 1ê°œ\n",
      "  - ì¶œíŒë¬¼: 0ê°œ\n",
      "\n",
      "cv_data01.json (ì˜ì–´):\n",
      "  - ì´ë¦„: Joanna Drummond\n",
      "  - ì´ë©”ì¼: jdrummond@cs.toronto.edu\n",
      "  - ì „í™”ë²ˆí˜¸: None\n",
      "  - ê²½ë ¥: 6ê°œ\n",
      "  - í•™ë ¥: 3ê°œ\n",
      "  - í”„ë¡œì íŠ¸: 0ê°œ\n",
      "  - ì¶œíŒë¬¼: 3ê°œ\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ë‘ ì´ë ¥ì„œì˜ íŒŒì‹± ê²°ê³¼ ìš”ì•½\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"  ğŸ“Š íŒŒì‹± ìš”ì•½\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "results = {\n",
    "    'cv_data00.json (í•œêµ­ì–´)': result_kr,\n",
    "    'cv_data01.json (ì˜ì–´)': result_en\n",
    "}\n",
    "\n",
    "for filename, result in results.items():\n",
    "    print(f\"\\n{filename}:\")\n",
    "    print(f\"  - ì´ë¦„: {result.get('basic_info', {}).get('name')}\")\n",
    "    print(f\"  - ì´ë©”ì¼: {result.get('contact_info', {}).get('email')}\")\n",
    "    print(f\"  - ì „í™”ë²ˆí˜¸: {result.get('contact_info', {}).get('phone')}\")\n",
    "    print(f\"  - ê²½ë ¥: {len(result.get('work_experiences', []))}ê°œ\")\n",
    "    print(f\"  - í•™ë ¥: {len(result.get('education', []))}ê°œ\")\n",
    "    print(f\"  - í”„ë¡œì íŠ¸: {len(result.get('projects', []))}ê°œ\")\n",
    "    print(f\"  - ì¶œíŒë¬¼: {len(result.get('publications', []))}ê°œ\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥ (ì„ íƒì‚¬í•­)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… íŒŒì‹± ê²°ê³¼ê°€ 'parsed_resumes_output.json' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\n"
     ]
    }
   ],
   "source": [
    "# íŒŒì‹± ê²°ê³¼ë¥¼ JSON íŒŒì¼ë¡œ ì €ì¥\n",
    "output_data = {\n",
    "    'cv_data00.json': result_kr,\n",
    "    'cv_data01.json': result_en\n",
    "}\n",
    "\n",
    "output_file = 'parsed_resumes_output.json'\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    json.dump(output_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"âœ… íŒŒì‹± ê²°ê³¼ê°€ '{output_file}' íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. ê°œë³„ í•„ë“œ ì ‘ê·¼ ì˜ˆì œ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ ===\n",
      "í•œêµ­ì–´ ì´ë ¥ì„œ - ì´ë¦„: ìµœì¬ê°•\n",
      "í•œêµ­ì–´ ì´ë ¥ì„œ - ì´ë©”ì¼: workd.official@gmail.com\n",
      "ì˜ì–´ ì´ë ¥ì„œ - ì´ë¦„: Joanna Drummond\n",
      "ì˜ì–´ ì´ë ¥ì„œ - ì´ë©”ì¼: jdrummond@cs.toronto.edu\n",
      "\n",
      "=== ê²½ë ¥ ì •ë³´ ===\n",
      "íšŒì‚¬: ì˜¤ì¼€ìŠ¤íŠ¸ë¡œ\n",
      "ì§ì±…: ML Engineer\n",
      "ê¸°ê°„: 2023.08 ~ í˜„ì¬\n",
      "í”„ë¡œì íŠ¸: 4ê°œ\n",
      "  - íšŒì‚¬ QA í™ˆí˜ì´ì§€ ì±—ë´‡ ê°œë°œ\n",
      "  - í•œêµ­í–‰ì •ì—°êµ¬ì› ë³´ê³ ì„œ ëª©ì°¨ë³„ ìš”ì•½ POC\n",
      "  - Â· ìš”ì•½ íŒŒì´í”„ë¼ì¸ ì¶”ë¡  ì†ë„ ìµœì í™”\n",
      "  - LLM ì™¸êµ­ì–´ Block LogitProcessor êµ¬í˜„\n",
      "\n",
      "=== í•™ë ¥ ì •ë³´ ===\n",
      "PhD - Computer Science (GPA: 3.83)\n",
      "M.S. - Computer Science (GPA: 3.93)\n",
      "B.S. - Computer Science (GPA: 3.73)\n"
     ]
    }
   ],
   "source": [
    "# íŠ¹ì • ì •ë³´ë§Œ ì¶”ì¶œí•˜ëŠ” ì˜ˆì œ\n",
    "\n",
    "# ì´ë¦„ê³¼ ì´ë©”ì¼ë§Œ ì¶”ì¶œ\n",
    "print(\"\\n=== ê¸°ë³¸ ì •ë³´ ì¶”ì¶œ ===\")\n",
    "print(f\"í•œêµ­ì–´ ì´ë ¥ì„œ - ì´ë¦„: {result_kr['basic_info']['name']}\")\n",
    "print(f\"í•œêµ­ì–´ ì´ë ¥ì„œ - ì´ë©”ì¼: {result_kr['contact_info']['email']}\")\n",
    "print(f\"ì˜ì–´ ì´ë ¥ì„œ - ì´ë¦„: {result_en['basic_info']['name']}\")\n",
    "print(f\"ì˜ì–´ ì´ë ¥ì„œ - ì´ë©”ì¼: {result_en['contact_info']['email']}\")\n",
    "\n",
    "# ê²½ë ¥ ì •ë³´ ì ‘ê·¼\n",
    "print(\"\\n=== ê²½ë ¥ ì •ë³´ ===\")\n",
    "for exp in result_kr['work_experiences']:\n",
    "    print(f\"íšŒì‚¬: {exp['company_name']}\")\n",
    "    print(f\"ì§ì±…: {exp['position']}\")\n",
    "    print(f\"ê¸°ê°„: {exp['start_date']} ~ {exp['end_date'] or 'í˜„ì¬'}\")\n",
    "    if exp['projects']:\n",
    "        print(f\"í”„ë¡œì íŠ¸: {len(exp['projects'])}ê°œ\")\n",
    "        for proj in exp['projects']:\n",
    "            print(f\"  - {proj['name']}\")\n",
    "\n",
    "# í•™ë ¥ ì •ë³´ ì ‘ê·¼\n",
    "print(\"\\n=== í•™ë ¥ ì •ë³´ ===\")\n",
    "for edu in result_en['education']:\n",
    "    print(f\"{edu['degree']} - {edu['major']} (GPA: {edu['gpa']})\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jobpt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
